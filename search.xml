<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[多线程编程--基础知识]]></title>
    <url>%2Fmutlithreading%2Fmultithreading-base.html</url>
    <content type="text"><![CDATA[线程（Thread）是操作系统能够进行运算调度的最小单位，java线程中创建的、引用的对象在jvm内存中是如何存放的，线程间是如何进行通信的呢，线程发生异常了jvm又是如何处理的呢，接下来让我们从线程的基础知识开始一步一步地了解。 ¶线程基础知识 ¶什么是线程 线程（Thread）是操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务。 ¶如何创建线程 继承Thread类 123456789101112131415161718/** * 继承Thread类 */static class ThreadTest extends Thread&#123; @Override public void run()&#123; super.run(); System.out.println("Hello World! This is my first Thread."); &#125;&#125;@Testpublic void extendsThreadTest() throws InterruptedException &#123; ThreadTest threadTest = new ThreadTest(); threadTest.start(); System.out.println("运行结束。"); Thread.sleep(10);&#125; 实现Runnable接口 123456789101112131415161718/** * 实现Runnable接口 */static class RunnableTest implements Runnable&#123; @Override public void run() &#123; System.out.println("Hello World! This is my first Thread."); &#125;&#125; @Testpublic void implementsRunnableTest() throws InterruptedException &#123; RunnableTest runnableTest = new RunnableTest(); Thread thread = new Thread(runnableTest); thread.start(); Thread.sleep(1000); System.out.println("运行结束。");&#125; ¶线程的状态 Java中的线程一共有六种状态： NEW（初始化状态） RUNNABLE（可运行 / 运行状态） BLOCKED（阻塞状态） WAITING（无时限等待） TIMED_WAITING（有时限等待） TERMINATED（终止状态） 线程可以在这六种状态之间相互转换，如图所示： ¶内存模型 ¶java内存模型 每一个运行在Java虚拟机里的线程都拥有自己的线程栈，存放当前线程运行的信息。 所有原始类型的本地变量都存放在线程栈上，因此对其它线程不可见。 所有引用类型的本地变量都存放在堆中，线程栈保存该对象的引用，因此其他线程只要有该对象的引用都可以访问。 Java程序中无论由哪个对象创建的对象，不管是原始类型对象，还是引用类型对象，都是存放在堆里面。 接下来让我们先看看一段具体代码，这些变量都存放在JVM的什么位置。 12345678910111213141516171819202122232425262728293031323334public class MemoryModel &#123; private static class MemorySharedObject &#123; private static MemorySharedObject sharedObject = new MemorySharedObject(); public Integer object2 = new Integer(222); public Integer object4 = new Integer(444); public long member1 = 12345L; public long member2 = 67890L; &#125; private static List&lt;Object&gt; list = Collections.synchronizedList(new ArrayList&lt;&gt;()); @Test public void test() throws InterruptedException &#123; new Thread(this::methodOne).start(); new Thread(this::methodOne).start(); Thread.sleep(100000); &#125; private void methodOne() &#123; int localVariable1 = 999; MemorySharedObject localVariable2 = MemorySharedObject.sharedObject; list.add(localVariable2); methodTwo(); &#125; private void methodTwo() &#123; Integer localVariable1 = new Integer(4321); list.add(localVariable1); &#125;&#125; 当test用例执行的时候，各个变量在jvm内存中存放位置如下图所示： 上图中每个线程执行methodOne()都会在它们对应的线程栈上创建localVariable1和localVariable2的私有拷贝。localVariable1为基础类型对象只存在于线程栈上，localVariable2为堆内存中Object3的引用。methodTwo方法中的localVariable1都会各自在堆上创建一个对象object1和object5，线程栈中存放这两个对象的引用。 执行test用例的时候，我们执行如下两个步骤： jmap -dump:format=b,file=./heap_dump.txt 12792 dump出jvm内存后，使用mat进行分析，可以找到本例中对象的情况 分析结果如下如所示： ¶硬件内存模型 ¶java内存模型与硬件内存模型的关系 ¶同步异步 同步和异步关注的是：消息通信机制(synchronous communication/ asynchronous communication)。 ¶同步（Synchronous） 同步方法调用一旦开始，调用者必须等到方法调用返回后，才能继续后续的行为，如下图所示： 打电话 B/S模式 ¶异步（Asynchronous） 异步方法调用更像一个消息传递，一旦开始，方法调用就会立即返回，调用者就可以继续后续的操作。而，异步方法通常会在另外一个线程中，“真实”地执行着。整个过程，不会阻碍调用者的工作，如下图所示： 发短信 ajax 消息队列 ¶阻塞和非阻塞 阻塞和非阻塞：强调的是程序在等待调用结果（消息，返回值）时的状态。 阻塞调用是指调用结果返回之前，当前线程会被挂起，调用线程只有在得到结果之后才会返回。 非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。 ¶线程间通信 ¶共享对象 线程间发送信号的一个简单方式是在共享对象的变量里设置信号值，如下面代码所示： 123456789private static class MySignal &#123; private boolean hasDataToProcess = false; public synchronized boolean hasDataToProcess() &#123; return this.hasDataToProcess; &#125; public synchronized void setHasDataToProcess(boolean process)&#123; this.hasDataToProcess = process; &#125;&#125; 线程A在一个同步块里设置boolean型成员变量hasDataToProcess为true，线程B也在同步块里读取hasDataToProcess这个成员变量。 12345678910111213141516171819@Testpublic void test_share_signal() &#123; MySignal signal = new MySignal(); new Thread(() -&gt; &#123; while(!signal.hasDataToProcess()) &#123; System.out.println("线程A未接收到信号，sleep 1000ms"); sleep(1000); &#125; System.out.println("线程A接收到信号了，开始处理：" + data.remove(0)); &#125;).start(); sleep(10000); new Thread(() -&gt; &#123; System.out.println("线程B设置信号"); data.add("线程B设置的数据"); signal.setHasDataToProcess(true); &#125;).start();&#125; 注意：线程A和B必须获得指向一个MySignal共享实例的引用，否则线程A将收不到信号。 ¶wait(),notify()和notifyAll() 通过共享对象，循环检测信号是否被设置，如果没有被设置则进入等待，等待的间隔时间设置过短则对cpu消耗过大，等待的间隔时间设置过长则消息接收不及时。 Java有一个内建的等待机制来允许线程在等待信号的时候变为非运行状态。java.lang.Object 类定义了三个方法，wait()、notify()和notifyAll()来实现这个等待机制。 一个线程一旦调用了任意对象的wait()方法，就会变为非运行状态，直到另一个线程调用了同一个对象的notify()方法。为了调用wait()或者notify()，线程必须先获得那个对象的锁，也就是说，线程必须在同步块里调用wait()或者notify()，否则将抛出java.lang.IllegalMonitorStateException异常。 1234567891011121314151617181920212223@Test public void test_wait_notify() &#123; Object monitor = new Object(); List&lt;String&gt; data = new ArrayList&lt;&gt;(); Thread thread = new Thread(() -&gt; &#123; try &#123; synchronized (monitor) &#123; System.out.println(&quot;子线程开始等待notify信号&quot;); monitor.wait(); &#125; System.out.println(&quot;子线程接收到notify信号了，开始处理：&quot; + data.remove(0)); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); thread.start(); sleep(3000); data.add(&quot;主线程调用notify方法&quot;); synchronized (monitor) &#123; monitor.notify(); &#125; &#125; 一旦线程调用了wait()方法，它就释放了所持有的监视器对象上的锁。这将允许其他线程也可以调用wait()或者notify()。一旦一个线程被唤醒，不能立刻就退出wait()的方法调用，直到调用notify()的线程退出了它自己的同步块。换句话说：**被唤醒的线程必须重新获得监视器对象的锁，才可以退出wait()的方法调用，因为wait方法调用运行在同步块里面。**如果多个线程被notifyAll()唤醒，那么在同一时刻将只有一个线程可以退出wait()方法，因为每个线程在退出wait()前必须获得监视器对象的锁。 ¶异常处理 ¶Thread默认的异常处理 线程都不允许抛出未捕获的checked exception（比如sleep时的InterruptedException），也就是说各个线程需要自己把自己的checked exception处理掉。我们可以查看一下Thread类的run()方法声明，方法声明上没有对抛出异常进行约束。 12345678910//Thread类中@Overridepublic void run() &#123; if (target != null) &#123; target.run();//实际上直接调用Runnable实例的run方法 &#125;&#125;//Runnable接口中public abstract void run(); 线程是独立执行的代码片断，线程的问题应该由线程自己来解决，而不要委托到外部。 ¶未捕获的异常去哪儿了 一个异常被抛出后，如果没有被捕获处理，则会一直向上抛。异常一旦被Thread.run() 抛出后，就不能在程序中对异常进行捕获，最终只能由JVM捕获。 1234567891011121314151617181920212223 @Test public void test_thread_exception() &#123; new Thread(() -&gt; &#123;int a = 1/0;&#125;).start(); &#125;// 执行结果Exception in thread "Thread-0" java.lang.ArithmeticException: / by zero at com.teddy.thread.basic.ThreadExceptionTest.lambda$thread_exception$0(ThreadExceptionTest.java:9) at java.lang.Thread.run(Thread.java:748) @Test public void test_catch_thread_exception() &#123; try &#123; new Thread(() -&gt; &#123;int a = 1/0;&#125;).start(); &#125; catch (Exception e) &#123; System.out.println("捕获到线程抛出的异常！"); e.printStackTrace(); &#125; &#125;// 执行结果Exception in thread "Thread-0" java.lang.ArithmeticException: / by zero at com.teddy.thread.basic.ThreadExceptionTest.lambda$test_catch_thread_exception$1(ThreadExceptionTest.java:18) at java.lang.Thread.run(Thread.java:748) ¶JVM如何处理线程中抛出的异常 查看Thread类的源码，我们可以看到有个dispatchUncaughtException方法，此方法就是用来处理线程中抛出的异常的。JVM会调用dispatchUncaughtException方法来寻找异常处理器(UncaughtExceptionHandler)，处理异常。 12345678910// 向handler分派未捕获的异常。该方法仅由JVM调用。private void dispatchUncaughtException(Throwable e) &#123; getUncaughtExceptionHandler().uncaughtException(this, e);&#125;// 获取用来处理未捕获异常的handler，如果没有设置则返回当前线程所属的ThreadGrouppublic UncaughtExceptionHandler getUncaughtExceptionHandler() &#123; return uncaughtExceptionHandler != null ? uncaughtExceptionHandler : group;&#125; UncaughtExceptionHandler必须显示的设置，否则默认为null。若为null，则使用线程默认的handler，即该线程所属的ThreadGroup。ThreadGroup自身就是一个handler，查看ThreadGroup的源码就可以发现，ThreadGroup实现了Thread.UncaughtExceptionHandler接口，并实现了默认的处理方法。默认的未捕获异常处理器处理时，会调用 System.err 进行输出，也就是直接打印到控制台了。 123456789101112131415public void uncaughtException(Thread t, Throwable e) &#123; if (parent != null) &#123; // 父级优先处理 parent.uncaughtException(t, e); &#125; else &#123; Thread.UncaughtExceptionHandler ueh = Thread.getDefaultUncaughtExceptionHandler(); if (ueh != null) &#123; ueh.uncaughtException(t, e); &#125; else if (!(e instanceof ThreadDeath)) &#123; // 没有配置handler时，默认直接打印到控制台 System.err.print("Exception in thread \"" + t.getName() + "\" "); e.printStackTrace(System.err); &#125; &#125;&#125; ¶产考文献 http://ifeve.com/java-concurrency-thread-directory/ http://tutorials.jenkov.com/java-concurrency/index.html 《深入Java虚拟机：JVM高级特性与最佳实践（第2版）》]]></content>
      <categories>
        <category>java多线程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>java多线程</tag>
        <tag>多线程编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程编程--基础知识]]></title>
    <url>%2Fmutlithreading%2Fmultithreading-juc.html</url>
    <content type="text"><![CDATA[¶内存模型 ¶同步异步 ¶线程间通信 ¶异常处理 ¶产考文献 http://tutorials.jenkov.com/java-concurrency/java-memory-model.html]]></content>
      <categories>
        <category>java多线程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>java多线程</tag>
        <tag>多线程编程</tag>
        <tag>JUC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程编程--基础知识]]></title>
    <url>%2Fmutlithreading%2Fmultithreading-models.html</url>
    <content type="text"><![CDATA[¶内存模型 ¶同步异步 ¶线程间通信 ¶异常处理 ¶产考文献 http://tutorials.jenkov.com/java-concurrency/java-memory-model.html]]></content>
      <categories>
        <category>java多线程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>java多线程</tag>
        <tag>多线程编程</tag>
        <tag>并发模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UML基础]]></title>
    <url>%2Fengineering%2Fuml.html</url>
    <content type="text"><![CDATA[近几年来，面向对象几乎成为软件技术的代名词。而UML是面向对象方法的一面旗帜，谈到面向对象的分析和设计就不能不谈到UML。如今UML也成为面向对象分析和设计事实上的行业标准。然而什么是UML，如何利用UML将一份原始需求经过层层分析和推导，最终形成可执行的代码？ ¶为什么需要UML 面向过程还是面向对象？ ¶面向过程方法 面向过程方法认为我们的世界是由一个个相互关联的小系统组成的，每个小系统都有着明确的开始和明确的结束，开始和结束之间有着严谨的因果关系。只要我们将这个小系统中的每一个步骤和影响这个小系统走向的所有因素都分析出来，我们就能完全定义这个系统的行为。 ¶面向对象方法 ​ 面向对象（Object Oriented，简称OO）方法将世界看作一个个相互独立的对象，相互之间并无因果关系，它们平时是“鸡犬之声相闻，老死不相往来”的。只有在某个外部力量的驱动下，对象之间才会依据某种规律相互传递信息。这些交互构成了这个生动世界的一个“过程”。在没有外力的情况下，对象则保持着“静止”的状态。 对象是怎么被抽象出来的？现实世界和对象世界看上去差别是那么大，为什么要这么抽象而不是那么抽象呢？（Why） 一种把现实世界映射到对象世界的方法 对象世界由于其灵活性，可以任意组合，可是我们怎么知道某个组合就正好满足了现实世界的需求呢？什么样的组合是好的，什么样的组合是差的呢？（How） 一种从对象世界描述现实世界的方法 抛开现实世界，对象世界是如此的难以理解。如果只给我一个对象组合，我怎么才能理解它表达了怎样的含义呢？（What） 一种验证对象世界行为是否正确反映了现实世界的方法 ¶什么是UML 统一建模语言（Unified Modeling Language）是一种建模用的语言，而所有的语言都是由基本词汇和语法两个部分构成的，UML也不例外。UML定义了一些建立模型所需要的、表达某种特定含义的基本元素，这些元素称为元模型，相当于语言中的基本词汇，例如用例、类等。另外，UML还定义了这些元模型互相之间关系的规则，以及如何用这些元素和规则绘制图形以建立模型来映射现实世界；这些规则和图形称为表示法或视图（View），相当于语言中的语法。 统一 秦始皇历史上的一大功绩便是统一语言和度量衡 统一的目标就是形成标准，任何一种组件化开发模式背后都有一个标准在规范和指导，可以说没有标准就没有工业现代化，没有标准就没有编程组件化，这就是标准的意义。 ¶从现实世界到业务模型 这是把现实世界映射到对象世界的第一步。UML采用用例这一关键元素捕获了现实世界的人要做的事，再通过用例场景、领域模型等视图将现实世界的人、事、物、规则这些构成现实世界的元素用UML这种语言描述出来。 ¶从业务模型到概念模型 这是从对象世界来描述现实世界的方法。用例所代表的现实的业务过程，被“边界”、“控制”、“实体”以及“包”、“组件”等概念替代。而这些概念是可以被计算机理解的，是抽象化了的对象。现实世界千差万别的业务，都用“边界”、“控制”、“实体”这几个固定的元素来描述，也就是说，现实具体的业务被“抽象”成几个固定的概念。同时，这些概念还可以用“包”、“组件”等这些与现实世界毫不相关的纯计算机逻辑术语包装。这说明概念模型是计算机视角，或者说是对象视角，而且这些对象视角的分析类所描述的信息是从映射了现实世界的业务模型转化而来的。 ¶从概念模型到设计模型 这是验证对象世界是否正确反映了现实世界的方法。“边界”、“控制”、“实体”这些对象化的概念，虽然是计算机可以理解的，但它并不是真正的对象实例，即它们并不是可执行代码，概念模型只是纸上谈兵。真正的对象世界行为是由Java类、C++类、EJB、COM+等这些可执行代码构成的。设计模型是概念模型在特定环境和条件下的“实例”化，实例化后的对象行为“执行”了概念模型描述的那些信息，因此设计模型得以通过概念模型追溯到原始需求来验证对象世界是否正确反映了现实世界。 如果把三个模型的建立过程综合起来，如下图所示： 从中我们可以更清楚地看到面向对象的困难是如何在模型的转化过程中解决的。这一过程看来是有规律、可推导、可追溯的过程。 ¶UML核心视图 ¶静态视图 故名思义，静态视图就是表达静态事物的。它只描述事物的静态结构，而不描述其动态行为。静态视图包括用例图、类图和包图。 ¶用例图 用例视图采用参与者和用例作为基本元素，以不同的视角展现系统的功能性需求。 ¶业务用例视图 业务用例视图使用业务主角和业务用例展现业务建模的结果。 业务主角视图 从业务主角视角来展示业务主角在业务中使用哪些业务用例来达成业务目标。如果业务主角认为其所有目标都已经齐全，则认为针对此主角的业务用例定义完成，以此来检查是否有遗漏的业务用例没有发现。 业务模块视图 从业务模块视角来展示业务领域的业务目标，将参与了达成这一业务目标的业务主角与业务用例展现在这个视图中。如果这项业务能够被这些业务主角和业务用例完整地说明，则认为针对此业务模块的业务用例定义完成，以此来检查是否有遗漏的业务用例没有发现。 ¶业务用例实现视图 ​ 业务用例实现视图展现业务用例有哪些实现途径。业务用例是业务需求，而业务用例实现则是业务的实现途径，从软件工程的角度说，这个视图展示了需求的可追溯特点。 ¶概念用例视图 ​ 概念用例视图用于展现从业务用例中经过分析分解出来的关键概念用例，并表示概念用例和业务用例之间的关系。一般来说这些关系有扩展、包含和精化。 ¶系统用例视图 ​ 系统用例视图展现系统范围，将对业务用例进行分析以后得到的系统用例展现出来。系统用例视图就是系统的开发范围。 ¶系统用例实现视图 ​ 如果一个系统用例有多种实现方式，也应当为其绘制实现视图。 ​ 在实际项目中，不是所有的用例视图都一定要采用。根据情况可进行适当裁减，例如只保留业务用例视图和系统用例视图。在许多项目中实际上只有系统用例视图，不论如何，我们应当知道用例图在不同的生命周期阶段还有不同的表达，从而选择适合自己项目的视图。 ¶常用元素参考 ¶类图 类图用于展示系统中的类及其相互之间的关系。本质上说，类图是现实世界问题领域的抽象对象的结构化、概念化、逻辑化描述。 ¶概念层类图 概念层的观点认为，在这个层次的类图描述的是现实世界中问题领域的概念理解，类图中表达的类与现实世界的问题领域有着明显的对应关系，类之间的关系也与问题领域中实际事物的关系有着明显的对应关系。 ¶说明层类图 ​ 说明层的观点认为，在这个层次的类图考察的是类的接口而不是实现，类图中表达的类和类关系应当是对问题领域在接口层次抽象的描述。 ¶实现层类图 ​ 实现层观点认为，类是实现代码的描述，类图中的类直接映射到可执行代码。 ¶常用元素参考 ¶包图 ​ 在实际项目中，建模过程中获得的元素是非常多的，如果要将这些元素的关系都绘制出来，将如同蜘蛛网一样难以辨别。通过包这个容器来从大到小、从粗到细地建立关系是一种很好的办法。 ​ 在UML所有视图中，包图或许是最自由，约束最小的一种。除了特定的版型之外，包几乎可以用在任何阶段。 ¶动态视图 故名思义，动态视图是描述事物动态行为的。需要注意的是，动态视图不能够独立存在，它必须特指一个静态视图或UML元素，说明在静态视图规定的事物结构下它们的动态行为。动态视图包括活动图、状态图、时序图和协作图。 ¶活动图 活动图描述了为了完成某一个目标需要做的活动以及这些活动的执行顺序。UML中有两个层面的活动图，一种用于描述用例场景，另一种用于描述对象交互。 ¶用例活动图 用例活动图是最经常使用的。用例表达了参与者的一个目标，用例场景则描述了如何来达到这个目标。活动图用来描述用例场景，也就是通常所说的业务流程。 ¶对象活动图 ​ 对象活动图用于展示对象的交互。 ¶泳道 ​ 上面的活动图描述了业务流程中活动的执行顺序，却没有描述出谁来执行这些活动，即执行业务流程的职责被遗漏了。泳道技术的引入多多少少解决了活动图不能描述对象职责的遗憾。 ​ 状态图是很有用的技术，尤其在描述单个复杂对象的行为时非常有助于我们理解一个对象的行为。但是在建模时并不需要对每个对象都绘制状态图。建议，仅对领域模型中最为关键的业务对象，尤其是当其在一个或多个用例场景中参与了多个活动时，才对其建模。 ¶常用元素参考 ¶状态图 ​ 状态图显示一个状态机，通常使用状态图来说明业务角色或业务实体可能的状态——导致状态转换的事件和状态转换引起的操作。状态机主要用于描述对象的状态变化以确定何种行为改变了对象状态，以及对象状态变化对系统的影响。 ¶常用元素参考 ¶时序图 ​ 时序图用于描述按时间顺序排列的对象之间的交互模式；它按照参与交互的对象所具有的“生命线”和它们相互发送的消息来显示这些对象。在时序图中包含对象和主角实例，以及说明它们如何交互的消息。 ¶业务模型时序图 ​ 业务模型时序图用于为领域模型中的业务实体交互建模，其目标是实现业务用例。在绘制业务实体时序图之前，你应当已经绘制了业务用例实现过程的活动图。 ¶概念模型时序图 ​ 概念用例时序图通常是依据业务模型场景图来绘制的，它将业务模型场景用分析类重新绘制一遍，这样，既保留了实际业务需求，又得到了计算机实现的基本理念。 ¶设计模型时序图 ​ 设计模型时序图使用设计类作为对象绘制。目标是实现概念模型中的某个事件流，一般以一个完整交互为单位，消息细致到方法级别。 ​ 时序图的三种应用场合是在建模过程中经常使用的动态视图。除了这些场合，在任何时候需要表达对象间的交互时，或者想分析对象的职责和接口时都可以使用时序图。 ¶常用元素参考 ¶协作图 ¶业务模型协作图 ​ 业务模型协作图同样采用业务实体来绘制，目标也是实现用例场景。不过有时候协作图并不要求实现完整的场景，只需要将影响对象的关键消息绘制出来即可。因为协作图更在意的是对象的结构及其相互的影响。 某些建模工具（rose powerdesigner）可以直接把时序图转化为协作图 ¶概念模型协作图 ​ 与时序图相同，概念阶段的协作图采用分析类来绘制，目标是实现业务用例。同样这个阶段的协作图已经带有计算机理解。 ¶设计模型协作图 ​ 与时序图相同，设计模型协作图使用设计类为对象来绘制。目标是实现概念模型中的某个事件流，一般以一个完整交互为单位，消息细致到方法级别。 ¶常用元素参考 ¶参考文献 《大象：Thinking in UML（第二版）》]]></content>
      <categories>
        <category>软件工程</category>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>软件开发</tag>
        <tag>UML</tag>
        <tag>统一建模语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[软件开发模型]]></title>
    <url>%2Fengineering%2Fsoftware-develop-model.html</url>
    <content type="text"><![CDATA[第一次接触软件工程还是在学校的课本上，初识软件开发模型（或软件生命周期模型），工作几年之后对其终于有了一些了解。 趁着这次读《系统架构设计师教程》，做个读书笔记。 ¶软件开发生命周期 ​ 传统的软件生命周期是指软件产品从形成概念开始，经过定义、开发、使用和维护，直到最后被废弃（不能再使用）为止的全过程。 ¶软件开发模型 ​ 软件生存周期模型又称软件开发模型（software develop model）或软件过程模型（software process model），它是从某一个特定角度提出的软件过程的简化描述。 ​ 软件过程模型的基本概念：软件过程是制作软件产品的一组活动以及结果，这些活动主要由软件人员来完成，软件活动主要如下： 软件描述 软件开发 软件有效性验证 软件进化 软件过程模型是软件工程的重要内容，它为软件工程管理提供里程碑，为软件开发过程提供原则和方法。 ¶瀑布模型 瀑布模型（waterfall model）可以说是最早使用的软件生命周期模型之一。该模型描述的活动从一个阶段到另一个阶段逐次下降，它的工作流程形式上又很想瀑布，该模型如下图所示： 特点: 阶段间具有顺序性和依赖性: 因果关系紧密相连：前一阶段完成后，才能开始后一阶段。 前一个阶段工作的结果是后一个阶段工作的输入 质量保证: 每个阶段必须交付出合格的文档 对文档进行审核 缺点： 软件需求分析的准确性很难确定 初始版本周期长 如果改变需求，代价巨大 ¶原型模型 ​ 原型模型（prototype model）又称快速原型。由于瀑布模型的缺点，人们借助建筑师、工程师建造原型的经验，提出了原型模型。原型模型主要有两个阶段，如下图所示： 原型开发阶段：根据用户提出的软件系统定义，快速地开发一个原型。 利用模拟软件系统的人机界面和人机交互方式。 真正开发一个原型。 找一个或多个正在运行的类似软件进行比较。 目标软件开发阶段。 使用原型模型应该注意： 要有一定的开发环境和工具支持。 经过对原型的若干次修改，应收敛到目标范围内，否则可能会失败。 用户对系统模糊不清，无法准确回答目标系统的需求。 对于大型软件来说，原型可能非常复杂而难以快速形成，如果没有现成的，就不应该考虑原型法。 ¶螺旋模型 ​ 螺旋模型（Spiral Model）是在快速原型的基础上扩展而成，实际上，它是软件生命周期模型与原型模型的一个结合，如下图所示： 该模型将整个软件开发流程分为多个阶段，每个阶段都由4部分组成： 目标设定 风险分析 开发和有效性验证 评审 螺旋模型的软件开发过程实际上是上述4个部分的迭代过程，每迭代一次，螺旋线就增加一周，代表软件的一个新版本。经过若干次迭代后，系统应尽快收敛到用户允许或可以接受的目标范围。 优点: 设计上的灵活性,可以在项目的各个阶段进行变更。 以小的分段来构建大型系统，使成本计算变得简单容易。 客户始终参为保证了项目不偏离正确方向以及项目的可控性。 客户始终掌握项目的最新信息，从而他或她能够和管理层有效地交互。 客户认可这种公司内部的开发方式带来的良好的沟通和高质量的产品。 缺点: ​ 很难让用户确信这种演化方法的结果是可以控制的。建设周期长，而软件技术发展比较快，所以经常出现软件开发完毕后，和当前的技术水平有了较大的差距，无法满足当前用户需求。 ¶增量模型 增量模型（Incremental Model）把待开发的软件系统模块化，将每个模块作为一个增量组件，从而分批次地分析、设计、编码和测试这些增量组件，如下图所示： 困难: 每个新的构件集成到现有的软件结构中必须破坏原来以开发的产品，所以必须定义很好的接口。 优点: 短时间内向用户提供可完成部分工作的产品。 逐步增加产品功能可以使用户有时间了解和适应新产品。 开放结构的软件拥有的维护性明显好于封闭结构的软件。 缺点： 容易退化为边做边改模型，从而使软件过程的控制失去整体性。 如果增量包之间存在相交的情况且未很好处理，则必须做全盘系统分析。 ¶喷泉模型 ​ 喷泉模型（fountain model）是一种以用户需求为动力，以对象为驱动的模型，主要用于描述面向对象的软件开发过程。该模型认为软件开发过程自下而上周期的各阶段是相互迭代和无间隙的特性，该模型如下图所示： 优点: 喷泉模型不像瀑布模型那样，需要分析活动结束后才开始设计活动，设计活动结束后才开始编码活动。 该模型的各个阶段没有明显的界限，开发人员可以同步进行开发。 可以提高软件项目开发效率，节省开发时间，适应于面向对象的软件开发过程。 缺点: 由于喷泉模型在各个开发阶段是重叠的，因此在开发过程中需要大量的开发人员，因此不利于项目的管理。 这种模型要求严格管理文档，使得审核的难度加大，尤其是面对可能随时加入各种信息、需求与资料的情况。 ¶敏捷开发 敏捷开发以用户的需求进化为核心，采用迭代、循序渐进的方法进行软件开发，其核心思想主要有以下三点： 适应型，而非可预测型。 以人为本，而非已过程为本。 迭代增量式的开发过程。 敏捷开发知识体系整体框架 ¶敏捷软件开发宣言 个体和交互胜过过程和工具。 以人为本，强调个体及个体间的沟通与协作在软件开发过程中的重要性。 可以工作的软件胜过面面俱到的文档。 目标导向，自解释的友好的代码和架构。 客户合作胜过合同谈判。 客户为先，理解客户的需求，懂得如何与客户合作。 响应变化胜过遵循计划。 拥抱变化，在客户断变化的需求中了解其真正的需要。 ¶敏捷宣言遵循的原则 我们最优先要做的是通过尽早的、持续的交付有价值的软件来使客户满意。 即使到了开发的后期，也欢迎改变需求。敏捷过程利用变化来为客户创造竞争优势。 经常性地交付可以工作的软件，交付的间隔可以从几个星期到几个月，交付的时间间隔越短越好。 在整个项目开发期间，业务人员和开发人员必须天天都在一起工作。 围绕被激励起来的个体来构建项目。给他们提供所需的环境和支持，并且信任他们能够完成工作。 在团队内部，最具有效果并且富有效率的传递信息的方法，就是面对面的交谈。 工作的软件是首要的进度度量标准。 敏捷过程提倡可持续的开发速度。责任人、开发者和用户应该能够保持一个长期的、恒定的开发速度。 不断地关注优秀的技能和好的设计会增强敏捷能力。 简单——使未完成的工作最大化的艺术——是根本的。 最好的构架、需求和设计是出自于自组织的团队。 每隔一定时间，团队会在如何才能更有效地工作方面进行反省，然后相应地对自己的行为进行调整。 ¶敏捷设计 ¶拙劣设计的症状 僵化性：设计难以改变。 脆弱性：设计易于遭到破坏。 牢固性：设计难以重用。 粘滞性：难以做正确的事情。 不必要的复杂性：过分设计。 不必要的重复：复制黏贴。 晦涩性：混乱的表达。 这些症状在本质上和代码的臭味相似，但是它们所处的层次稍高一些。它们是遍及整个软件结构的臭味，而不仅仅是一小段代码。 ¶面向对象的设计原则 SRP 单一职责原则：就一个类而言，应该仅有一个引起它变化的原因。 OCP 开放-封闭原则：软件实体（类、模块、函数等）应该是可以扩展的，但是不可修改。 LSP Liskov替换原则：子类型必须能够替换掉它们的及类型。 DIP 依赖倒置原则：抽象不应该依赖于细节，细节应该依赖于抽象。 ISP 接口隔离原则：不应该强迫客户依赖于它们不用的方法。接口属于客户，不属于它所在的类层次结构。 23种设计模式：http://www.runoob.com/design-pattern/design-pattern-intro.html 我们最常用的spring框架就使用了很多种设计模式，例如BeanFactory中的工厂模式，AOP中的代理模式。 参考文献： 《系统架构设计师教程》 《敏捷软件开发(原则模式与实践)》]]></content>
      <categories>
        <category>软件工程</category>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>软件开发模型</tag>
        <tag>software develop model</tag>
        <tag>软件生命周期模型 - 敏捷开发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Deepin install Typora]]></title>
    <url>%2Flinux%2Ftypora.html</url>
    <content type="text"><![CDATA[在Deepin系统商店中就有携带Typora，提是使用深度源，但是大家一般都换成阿里云等速度比较快的源。按照官方文档安装也是一大堆问题，后来采用Linux Mint的安装方式完美解决 12345678910# or use# sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys BA300B7755AFCFAEwget -qO - https://typora.io/linux/public-key.asc | sudo apt-key add -# add Typora's repositoryecho -e "\ndeb https://typora.io/linux ./" | sudo tee -a /etc/apt/sources.listsudo apt-get update# install typorasudo apt-get install typora 注：不要使用官方推荐的Deb和Ubuntu的那个安装方法，采用Linux Mint的。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Deepin</tag>
        <tag>Markdown</tag>
        <tag>Typora</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot + jpa + h2 单元测试实战]]></title>
    <url>%2Funit-test%2Fdb-test.html</url>
    <content type="text"><![CDATA[最近需要开发一个组件，里面会有数据库操作，但由于该组件是单独开发没有实际的数据库，数据库后期会创建到集成该组件的业务系统里面。所以想到用内存数据来做测试，也避免了拿真实数据库作测试时留下垃圾数据，而且速度还比较快。 经历了一顿操作，终于搭好了单元测试环境。 ¶POM文件 1234567891011121314151617181920212223242526272829303132333435&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- test dependency --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;!-- Import dependency management from Spring Boot --&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.1.2.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; ¶配置文件application.yml 12345678910111213141516171819202122232425spring: h2: console: enabled: true path: /console settings: web-allow-others: true trace: false datasource: name: dataSource platform: h2 driver-class-name: org.h2.Driver url: jdbc:h2:mem:test;MODE=PostgreSQL;DB_CLOSE_DELAY=-1;DATABASE_TO_UPPER=false; username: sa password: 123456 schema: - classpath:sql/create/01.CS_SCHEMA.sql - classpath:sql/create/02.CT_TABLE.sql data: - classpath:sql/data/02.I_T_TEST.sql jpa: show-sql: true hibernate: ddl-auto: none database-platform: org.hibernate.dialect.H2Dialect ¶创建DO层 Entity 12345678910111213@Entity@Table(name = "t_test", schema = "test")@Datapublic class TestDO implements Serializable &#123; private static final long serialVersionUID = 1L; @Id @Column(name = "id") private String id; // columns定义 // ···&#125; Repository 1234@Repositorypublic interface TestRepository extends JpaRepository&lt;TestDO,String&gt; &#123;&#125; JPA的使用和配置参考淋哥的：Spring data jpa使用总结 ¶单元测试 123456789101112@RunWith(SpringRunner.class)@SpringBootTest(classes =TestApplication.class)public class TestRepositoryTest &#123; @Resource private TestRepository testRepository; @Test public void test_table_should_have_one_record()&#123; Assert.assertEquals(1, testRepository.count()); &#125;&#125; TimeLimitTestApplication代码如下： 12345@SpringBootApplication@EnableJpaRepositories(basePackages = "com.teddy.repository")@EntityScan(basePackages = "com.teddy.entity")public class TestApplication &#123;&#125; ¶遇到的问题 table not found h2数据库初始化的时候，已经执行了初始化脚本，但是执行单元测试时找不到表，经过排查，发现创建数据库脚本如下： 1234567set search_path to test;commit;drop table if exists t_test;create table t_test( ···); 该脚本在真实数据库中执行没有任何问题，但是在h2数据库中，并不能将表正确的创建到test模式中，而是创建到PUBLIC模式中了，导致找不到表。 修改脚本如下： 1234567set search_path to test;commit;drop table if exists test.t_test;create table test.t_test( ···); 即可解决该问题。 schema not found 由于JPA不区分大小写，注解里面配置的都会转成小写（可以通过配置： spring.jpa.hibernate.naming.physical-strategy=org.hibernate.boot.model.naming.PhysicalNamingStrategyStandardImpl即可解决表名，但是schema都是小写）。而H2数据库是区分大小写的，因此可能导致schema not found。 只要统一大小写即可处理。]]></content>
      <categories>
        <category>单元测试</category>
      </categories>
      <tags>
        <tag>springboot</tag>
        <tag>jpa</tag>
        <tag>h2</tag>
        <tag>单元测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo搭建个人博客]]></title>
    <url>%2Fhexo%2Finit.html</url>
    <content type="text"><![CDATA[之前基于Hexo搭建了个人博客网站，最近换了个Linux系统，差不多又重新搭建了一遍hexo，而且还遇到了许多问题，所以在这里记录一下hexo的搭建方法。 ¶什么是Hexo Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 ¶安装前提 ¶Node.js (Should be at least nodejs 6.9) 直接使用已编译好的包 Node 官网已经把 linux 下载版本更改为已编译好的版本了，我们可以直接下载解压后使用： 12345wget https://nodejs.org/dist/v10.16.0/node-v10.16.0-linux-x64.tar.xz // 下载tar xf node-v10.16.0-linux-x64.tar.xz // 解压cd node-v10.16.0-linux-x64/ // 进入解压目录./bin/node -v // 执行node命令 查看版本v10.16.0 也可以进入Node官网下载最新版本：https://nodejs.org/ 解压文件的 bin 目录底下包含了 node、npm 等命令，我们可以使用 ln 命令来设置软连接： 12ln -s /usr/software/node-v10.16.0-linux-x64/bin/npm /usr/local/bin/ ln -s /usr/software/node-v10.16.0-linux-x64/bin/node /usr/local/bin/ ¶Git 这个就不用多介绍了：sudo apt-get install git ¶安装Hexo 1$ npm install -g hexo-cli 安装后会执行 hexo，会发现找不到命令，把hexo加入到软连接即可： 1ln -s /usr/software/node-v10.16.0-linux-x64/lib/node_modules/hexo-cli/bin/hexo /usr/local/bin/ ¶建站 参考官方文档即可：https://hexo.io/zh-cn/docs/setup ¶主题配置 参考官方文档即可：https://theme-next.org/ ¶启动 hexo server]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>个人博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo 下拉刷新]]></title>
    <url>%2Fhexo%2Fpull-refresh.html</url>
    <content type="text"><![CDATA[现在手机上大部分的app、网页都具备下拉刷新的功能，用着还挺爽的。 最近基于Hexo搭建的个人博客网站，默认居然不支持下拉刷新，索性就自己手动弄了一个下拉刷新。 ¶为什么要下拉刷新 现在浏览器不都有自带的刷新功能么？ 原因如下： 相较于点击右上角刷新按钮（还有可能要点两次，第一次先展开 menu bar，然后才能看到 refresh 按钮），直接了当地下拉刷新无疑提供了更好的用户体验 点击刷新按钮同步重载页面必然存在一定白屏时间，而通过下拉刷新的逻辑完全可以对于页面内容进行异步更新，其体验毫无疑问更加优秀 移动端特有 touch 相关事件，用户在移动设备上的触摸、滑动操作频繁，习惯已经养成，下拉刷新在提供更好的体验的同时，丝毫没有增加用户的学习成本 很多内容 + 社交的业务场景里面，主页面的存留时长极高且内容实时性强（如微博、知乎、头条等）, 这些 Native App 已经普遍向用户提供了这种(下拉刷新)更新页面内容的交互方式。作为一个 Web 开发者，如有志于在移动领域让 Web App 和 Native App 在体验方面一较高下，那 H5 页（异步）下拉刷新功能也算是不可或缺的一环 当然，还可以应对一些特殊场景 … （如 Webview 不提供刷新按钮 =,=） ¶如何添加 GitHub上找了很多类似的轮子，最终决定采用mescroll，下面就基于mescroll来实现hexo博客的下拉刷新功能。 ¶下载mescroll 到mescroll官网下载，mescroll.min.css,mescroll.min.js文件，放到themes/next/source/lib/mescroll文件夹下。 api文档请参考：http://www.mescroll.com/api.html?v=190426 ¶引入js文件和css文件 修改themes/next/layout/_custom/head.swig文件，添加如下内容： 123456&#123;#Custom head.#&#125;&lt;link rel=&quot;stylesheet&quot; href=&quot;&#123;&#123; url_for(theme.vendors._internal + &apos;/mescroll/mescroll.min.css?v=1.4.1&apos;) &#125;&#125;&quot;/&gt;&lt;script src=&quot;&#123;&#123; url_for(theme.vendors._internal + &apos;/mescroll/mescroll.min.js?v=1.4.1&apos;) &#125;&#125;&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt; 这样就能将js和css文件引入到HTML页面中。 ¶使用 根据mescroll的api文档添加pull-refresh.js文件： 123456789$(function()&#123; new MeScroll('body',&#123; down: &#123; callback: function()&#123; window.location.reload(); &#125; &#125; &#125;);&#125;); 存放在：themes/next/source/js/pull-refresh.js路径下，然后将其引入到HTML页面中，修改themes/next/layout/_scripts/commons.swig文件，将pull-refresh.js文件引入进去。 1234567891011&#123;% set js_commons = [ &apos;utils.js&apos;, &apos;motion.js&apos;, &apos;pull-refresh.js&apos; ]%&#125;&#123;% for common in js_commons %&#125; &lt;script src=&quot;&#123;&#123; url_for(theme.js) &#125;&#125;/&#123;&#123; common &#125;&#125;?v=&#123;&#123; version &#125;&#125;&quot;&gt;&lt;/script&gt;&#123;% endfor %&#125; 这里只所以不将pull-refresh.js一并放到head.swig文件中，是因为其中引用的jQuery引入顺序在head.swig之后。 到这里本来以为搞定了，结果打开页面发现页面会不停地刷新，然后调试源代码，发现mescroll初始的时候会根据配置自动刷新一次： mescroll.min.js 12345678910setTimeout(function() &#123; if (h.optDown.use &amp;&amp; h.optDown.auto &amp;&amp; f) &#123; if (h.optDown.autoShowLoading) &#123; h.triggerDownScroll() &#125; else &#123; h.optDown.callback &amp;&amp; h.optDown.callback(h) &#125; &#125; h.optUp.use &amp;&amp; h.optUp.auto &amp;&amp; !h.isUpAutoLoad &amp;&amp; h.triggerUpScroll()&#125;, 30) 于是乎修改mescroll的初始化代码： 12345678910$(function()&#123; new MeScroll('body',&#123; down: &#123; callback: function()&#123; window.location.reload(); &#125;, auto: false &#125; &#125;);&#125;); 至此，下拉刷新终于搞定了。 后来查看mescroll的参数说明，发现里面有提到auto的含义，这个故事告诉我们，使用前尽量多看看文档，也许能节省不少的时间。 参考链接 http://www.mescroll.com/index.html https://hexo.io/zh-cn/docs/]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>pull refresh</tag>
        <tag>下拉刷新</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 科学上网]]></title>
    <url>%2Flinux%2Fshadowsocks.html</url>
    <content type="text"><![CDATA[最近因为各种原因，从Windows转Linux，之前在Windows上用得非常爽的SSR客户端，但是在应用商店找了很久，都不好使。 最终找到electron-ssr，和Windows上的差不多。 ¶ShadowsocksR跨平台客户端 这是一个跨平台（支持Windows MacOS Linux系统）的ShadowsocksR客户端桌面应用，它功能丰富，支持windows版大部分功能，更有更多人性化功能。它是开源的，它来源于开源，回馈以开源。 功能特色 支持手动添加配置 支持服务器订阅更新，复制该地址测试 支持二维码扫描(请确保屏幕中只有一个有效的二维码)，扫描该二维码测试 支持从剪贴板复制、从配置文件导入等方式添加配置 支持复制二维码图片、复制SSR链接(右键应用内二维码，点击右键菜单中的复制) 支持通过点击ss/ssr链接添加配置并打开应用(仅Mac和Windows) 支持切换系统代理模式:PAC、全局、不代理 内置http_proxy服务，可在选项中开启或关闭 支持配置项变更 更多功能尽在任务栏菜单中 ¶下载 该软件的作者已经将其从GitHub上删除了，不再维护了，不过还好找到了备份，传送门：https://github.com/qingshuisiyuan/electron-ssr-backup/releases Deepin、Ubuntu系列下载electron-ssr-0.2.6.deb ¶安装和配置 sudo dpkg -i electron-ssr-0.2.6.deb 配置很简单，和Windows上的SSR客户端差不多，拷贝SSR的订阅连接，更新，然后选择喜欢的节点即可。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Deepin</tag>
        <tag>SSR</tag>
        <tag>ShadowsocksR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows换Linux之旅]]></title>
    <url>%2Flinux%2FWindows_to_Linux.html</url>
    <content type="text"><![CDATA[随着时代的发展，各种硬件软件急速发展，Windows都出到10了，越来越觉得七八年前的笔记本安装Windows10实在是太卡了。最近闲来无事，打算将其换成Linux，换完之后确实觉得比Windows流畅多了**_** ¶前言 本人对的Linux的了解可能比小白强一点点儿（自我感觉的，本次换系统来看其实就是小白）。 最开始安装的Ubuntu，感觉使用起来各种不爽。 默认安装的Firefox，对于一个程序猿来说，咋能少了Chrome呢 自带的vim编辑功能不全，还得删除了，重新安装一个 软件商店的应用太少，只能自己装 界面实在不太好看 于是乎，就思索着找其它的系统来代替，然后找到了Deepin，感觉确实比Ubuntu强太多了。 社区网站自带U盘启动制作工具，省心 安装Chrome作为默认浏览器 操作习惯更接近于Windows，对于从Windows转过来的用户比较友好 常用的软件都基本能在应用商店里面找到 界面是最大的亮点吧 国产，点个赞 下面就记录一下安装和配置Deepin的过程，为本次系统切换画上一个句号。 ¶安装 下载系统镜像：https://www.deepin.org/download/ 下载深度启动盘制作工具：https://www.deepin.org/original/deepin-boot-maker/ 使用下载深度启动盘制作工具，选择Deepin镜像，然后下一步选择U盘，OK，等待制作完成。 现在开始安装Deepin系统，开机前按F12进入引导选择页面（不同的主板可能不太一样，自行查询一下吧，有些比较老的得通过改BIOS设置才行） 由于我的机子是支持UEFI启动的，所以识别出的UEFI的U盘引导项。 接下来进入安装过程： 直接回车选择 Install Deepin。 语言选择-简体中文 设置用户名，主机名，密码 磁盘分区 普通模式，省心，直接安装就行了 专家模式，必须设置一个根目录分区“/”，其它磁盘可以挂载到其它目录 确认，开始安装，一杯咖啡的时间就能装好 安装完成，开始使用 ¶配置 ¶修改软件源 Deepin官方的软件源慢得跟蜗牛一样，在设置中指定镜像源又不能生效。 so，手工修改/etc/apt/sources.list文件。 修改前先备份一下 123456789101112sudo cp /etc/apt/sources.list /etc/apt/sources.list.baksudo vi /etc/apt/sources.list ## Generated by deepin-installer## 将官方源禁用## deb [by-hash=force] http://packages.deepin.com/deepin lion main contrib non-free## 设置阿里云，则将地址设置为deb [by-hash=force] https://mirrors.aliyun.com/deepin/ lion main contrib non-free#deb-src http://packages.deepin.com/deepin lion main contrib non-free 修改完成后:wq保存，然后刷新软件源列表，在终端执行： 1234sudo apt-get update# 软件更新，可选sudo apt-get upgrade 然后其它的工具就可以慢慢装啦 ¶修改文件夹权限 我在安装的时候将一块磁盘挂载到/home目录下，将代码下载到该目录下， 用idea开发的时候发现没有权限创建文件、文件夹和文件修改等权限，于是乎使出绝招： 1sudo chomd -R 777 /home ¶设置ll命令 在上面查看目录的过程中发现没有ll命令，然后网上查询了一下，发现是ll命令其实是 ls -l命令的别名,在deepin中这个配置被注释掉了。 使用下面的命令编辑配置文件打开即可： 1sudo vim ~/.bashrc 将alias ll=’ls -l’前的注释打开,然后source ~/.bashrc刷新一下即可 ¶设置su密码 deepin的用户默认就在sudo组里面，但是每次使用该命令都要输入密码，于是进行如下设置： 打开一个深度终端，然后输入下面的命令 1234sudo passwd [sudo] password for you ：---&gt; 输入你的密码（你现在这个用户的密码），不回显Enter new UNIX password: --- &gt; 设置root 密码Retype new UNIX password: --&gt; 重复密码 注：su和sudo的区别是： su的密码是root的密码，而sudo的密码是用户的密码； su直接将身份变成root，而sudo是以用户登录后以root的身份运行命令，不需要知道root密码； ¶设置sudo不需要每次都输入密码 如果想要sudo不每次都输入密码，则修改/etc/sudoers文件： sudo vi /etc/sudoers 然后在root ALL=(ALL:ALL) ALL下一行添加username ALL=(ALL:ALL) ALL 修改%sudo ALL=(ALL:ALL) ALL为%sudo ALL=(ALL:ALL) NOPASSWD:ALL 然后保存 搞定，本次安装过程记录到此为止，现在开始拥抱Linux吧。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Deepin</tag>
        <tag>Windows换Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[支持生产阻塞的线程池]]></title>
    <url>%2Fmutlithreading%2Fblocking-productor-threadpool.html</url>
    <content type="text"><![CDATA[在各种并发编程模型中，生产者-消费者模式大概是最常用的了。在实际工作中，对于生产消费的速度，通常需要做一下权衡。通常来说，生产任务的速度要大于消费的速度。一个细节问题是，队列长度，以及如何匹配生产和消费的速度。 一个典型的生产者-消费者模型如下： 在并发环境下利用J.U.C提供的Queue实现可以很方便地保证生产和消费过程中的线程安全。这里需要注意的是，Queue必须设置初始容量，防止生产者生产过快导致队列长度暴涨，最终触发OutOfMemory。 对于一般的生产快于消费的情况。当队列已满时，我们并不希望有任何任务被忽略或得不到执行，此时生产者可以等待片刻再提交任务，更好的做法是，把生产者阻塞在提交任务的方法上，待队列未满时继续提交任务，这样就没有浪费的空转时间了。阻塞这一点也很容易，BlockingQueue就是为此打造的，ArrayBlockingQueue和LinkedBlockingQueue在构造时都可以提供容量做限制，其中LinkedBlockingQueue是在实际操作队列时在每次拿到锁以后判断容量。 更进一步，当队列为空时，消费者拿不到任务，可以等一会儿再拿，更好的做法是，用BlockingQueue的take方法，阻塞等待，当有任务时便可以立即获得执行，建议调用take的带超时参数的重载方法，超时后线程退出。这样当生产者事实上已经停止生产时，不至于让消费者无限等待。 于是一个高效的支持阻塞的生产消费模型就实现了。 等一下，既然J.U.C已经帮我们实现了线程池，为什么还要采用这一套东西？直接用ExecutorService不是更方便？ 我们来看一下ThreadPoolExecutor的基本结构： 可以看到，在ThreadPoolExecutor中，BlockingQueue和Consumer部分已经帮我们实现好了，并且直接采用线程池的实现还有很多优势，例如线程数的动态调整等。 但问题在于，即便你在构造ThreadPoolExecutor时手动指定了一个BlockingQueue作为队列实现，事实上当队列满时，execute方法并不会阻塞，原因在于ThreadPoolExecutor调用的是BlockingQueue非阻塞的offer方法： 123456789101112public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); if (poolSize &gt;= corePoolSize || !addIfUnderCorePoolSize(command)) &#123; if (runState == RUNNING &amp;&amp; workQueue.offer(command)) &#123; if (runState != RUNNING || poolSize == 0) ensureQueuedTaskHandled(command); &#125; else if (!addIfUnderMaximumPoolSize(command)) reject(command); // is shutdown or saturated &#125;&#125; 这时候就需要做一些事情来达成一个结果：当生产者提交任务，而队列已满时，能够让生产者阻塞住，等待任务被消费。 关键在于，在并发环境下，队列满不能由生产者去判断，不能调用ThreadPoolExecutor.getQueue().size()来判断队列是否满。 线程池的实现中，当队列满时会调用构造时传入的RejectedExecutionHandler去拒绝任务的处理。默认的实现是AbortPolicy，直接抛出一个RejectedExecutionException。 几种拒绝策略在这里就不赘述了，这里和我们的需求比较接近的是CallerRunsPolicy，这种策略会在队列满时，让提交任务的线程去执行任务，相当于让生产者临时去干了消费者干的活儿，这样生产者虽然没有被阻塞，但提交任务也会被暂停。 123456789101112131415161718192021222324252627282930313233public static class CallerRunsPolicy implements RejectedExecutionHandler &#123; /** * Creates an &lt;tt&gt;AbortPolicy&lt;/tt&gt;. */ public CallerRunsPolicy() &#123; &#125; /** * Executes task r in the caller's thread, unless the executor * has been shut down, in which case the task is discarded. * @param r the runnable task requested to be executed * @param e the executor attempting to execute this task */ public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; if (!e.isShutdown()) &#123; r.run(); &#125; &#125;&#125; 但这种策略也有隐患，当生产者较少时，生产者消费任务的时间里，消费者可能已经把任务都消费完了，队列处于空状态，当生产者执行完任务后才能再继续生产任务，这个过程中可能导致消费者线程的饥饿。 参考类似的思路，最简单的做法，我们可以直接定义一个RejectedExecutionHandler，当队列满时改为调用BlockingQueue.put来实现生产者的阻塞： 1234567891011121314public class RejectedExecutionHandler() implements RejectedExecutionHandler &#123; @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) &#123; if (!executor.isShutdown()) &#123; try &#123; executor.getQueue().put(r); &#125; catch (InterruptedException e) &#123; // should not be interrupted &#125; &#125; &#125;&#125;; 这样，我们就无需再关心Queue和Consumer的逻辑，只要把精力集中在生产者和消费者线程的实现逻辑上，只管往线程池提交任务就行了。 相比最初的设计，这种方式的代码量能减少不少，而且能避免并发环境的很多问题。当然，你也可以采用另外的手段，例如在提交时采用信号量做入口限制等，但是如果仅仅是要让生产者阻塞，那就显得复杂了。]]></content>
      <categories>
        <category>java多线程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>java多线程</tag>
        <tag>ThreadPool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程编程与锁优化]]></title>
    <url>%2Fmutlithreading%2Fthread-lock.html</url>
    <content type="text"><![CDATA[多线程是在同一个程序内部并行执行，因此会对相同的内存空间进行并发读写操作。如果一个线程在读一个内存时，另一个线程正向该内存进行写操作，那进行读操作的那个线程将获得什么结果呢？是写操作之前旧的值？还是写操作成功之后的新值？或是一半新一半旧的值？或者，如果是两个线程同时写同一个内存，在操作完成后将会是什么结果呢？是第一个线程写入的值？还是第二个线程写入的值？还是两个线程写入的一个混合值？从下面的图我们可以窥知一二。 ¶多线程基础知识 ¶竞态条件与临界区 在同一程序中运行多个线程本身不会导致问题，问题在于多个线程访问了相同的资源。在一或多个线程向这些资源做了写操作时才有可能发生，只要资源没有发生变化,多个线程读取相同的资源就是安全的。 123456public class Counter &#123; protected long count = 0; public void add(long value)&#123; this.count = this.count + value; &#125;&#125; JVM并不是将这段代码：this.count = this.count + value;，视为单条指令来执行的，而是按照下面的顺序： 从内存获取 this.count 的值放到寄存器 将寄存器中的值增加value 将寄存器中的值写回内存 当线程A和线程B同时执行add方法时，他们的实际执行顺序可能如下： this.count = 0; A:读取 this.count 到一个寄存器 (0) B:读取 this.count 到一个寄存器 (0) B:将寄存器的值加2 B:回写寄存器值(2)到内存. this.count 现在等于 2 A:将寄存器的值加3 A:回写寄存器值(3)到内存. this.count 现在等于 3 当两个线程竞争同一资源时，如果对资源的访问顺序敏感，就称存在竞态条件。导致竞态条件发生的代码区称作临界区。上例中add()方法就是一个临界区,它会产生竞态条件。在临界区中使用适当的同步就可以避免竞态条件。 ¶共享资源 允许被多个线程同时执行的代码称作线程安全的代码，线程安全的代码不包含竞态条件，当多个线程同时更新共享资源时会引发竞态条件。 ¶局部变量 局部变量存储在线程自己的栈中。也就是说，局部变量永远也不会被多个线程共享。所以，基础类型的局部变量是线程安全的。下面是基础类型的局部变量的一个例子： 1234567891011121314151617181920212223242526272829/** * 方法内的变量是线程安全的 * @param username */private void addI(String username)&#123; try &#123; int num; if("a".equals(username))&#123; num = 100; System.out.println("a set over!"); Thread.sleep(2000); &#125;else&#123; num = 200; System.out.println("b set over!"); &#125; System.out.println(username + " num = " + num); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;&#125;@Testpublic void threadSetPrivateNumTest() throws InterruptedException &#123; Thread threadA = new Thread(()-&gt;addI("a")); Thread threadB = new Thread(()-&gt;addI("b")); threadA.start(); threadB.start(); Thread.sleep(3000);&#125; ¶局部的对象引用 对象的局部引用和基础类型的局部变量不太一样。尽管引用本身没有被共享，但引用所指的对象并没有存储在线程的栈内。所有的对象都存在共享堆中。如果在某个方法中创建的对象不会逃逸出（译者注：即该对象不会被其它方法获得，也不会被非局部变量引用到）该方法，那么它就是线程安全的。 1234567891011121314151617181920212223public class ThreadSafeTest &#123; private int instanceNum; private void addInstanceNum(String username)&#123; try &#123; if("b".equals(username))&#123; instanceNum = 200; System.out.println("b set over!"); &#125;else&#123; instanceNum = 100; System.out.println("a set over!"); Thread.sleep(2000); &#125; System.out.println(username + " num = " + instanceNum); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; @Test public void localObjectTest() throws InterruptedException &#123; addInstanceNum("a"); addInstanceNum("b"); &#125;&#125; 上面的示例中，localObject没有传递到其它线程中，那么它就是线程安全的，如果传到其它线程了呢？ 123456789@Test public void localObjectTest() throws InterruptedException &#123; ThreadSafeTest test = new ThreadSafeTest(); Thread threadA = new Thread(()-&gt;addInstanceNum("a")); Thread threadB = new Thread(()-&gt;addInstanceNum("b")); threadA.start(); threadB.start(); Thread.sleep(3000); &#125; 上面的示例中，localObject虽然是局部变量，但是在someMethod方法中将其引用传入到线程A和线程B中，他们的结果可能就不是预期的，那么localObject就不是线程安全的。 ¶对象成员 对象成员存储在堆上，如果两个线程同时更新同一个对象的同一个成员，那这个代码就不是线程安全的，详情参考竞态条件与临界区。 ¶线程控制逃逸规则 线程控制逃逸规则可以帮助你判断代码中对某些资源的访问是否是线程安全的。 12如果一个资源的创建，使用，销毁都在同一个线程内完成，且永远不会脱离该线程的控制，则该资源的使用就是线程安全的。 ¶多线程编程 ¶并发编程三要素 当多个线程要共享一个实例对象的值得时候，那么在考虑安全的多线程并发编程时就要保证下面3个要素： 原子性（Synchronized, Lock） 即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。 有序性(Volatile, Synchronized, Lock) 即程序执行的顺序按照代码的先后顺序执行。 可见性(Volatile, Synchronized, Lock) 可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。 ¶线程安全的实现方法 ¶互斥同步–悲观锁 互斥同步（Mutual Exclusion &amp; Synchronization）是常见的一种并发正确性保障手段。同步是指在多个线程并发访问共享数据时，保证共享数据在同一个时刻只被一个（或者是一些，使用信号量的时候）线程使用。而互斥是实现同步的一种手段，临界区（Critical Section）、互斥量（Mutex）和信号量（Semaphore）都是主要的互斥实现方式。因此，在这4个字里面，互斥是因，同步是果；互斥是方法，同步是目的。 这种方式实现的锁，总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁（共享资源每次只给一个线程使用（独占锁），其它线程阻塞，用完后再把资源转让给其它线程）。所以这也是悲观锁的思想的一种实现方式。 ¶synchronized 在Java中，最基本的互斥同步手段就是synchronized关键字，synchronized关键字经过编译之后，会在同步块的前后分别形成monitorenter和monitorexit这两个字节码指令，这两个字节码都需要一个reference类型的参数来指明要锁定和解锁的对象。如果Java程序中的synchronized明确指定了对象参数，那就是这个对象的reference；如果没有明确指定，那就根据synchronized修饰的是实例方法还是类方法，去取对应的对象实例或Class对象来作为锁对象。 123456789101112131415161718192021void methodB()&#123; synchronized (this)&#123; methodA(); &#125;&#125;这段代码编译之后的字节码如下： 0 aload_0 // 入栈this 1 dup // 复制栈顶元素 2 astore_1 // 将栈顶元素存储到局部变量表Slot 1中 3 monitorenter // 以栈顶元素（即this）作为锁，开始同步 4 aload_0 // 入栈this，用于调用methodA 5 invokevirtual #19 &lt;com/teddy/thread/basic/ThreadSafeTest$SyncMethodLockTest.methodA&gt; // 调用methodA 8 aload_1 // 入栈this，monitorexit的reference 9 monitorexit // 退出同步10 goto 18 (+8) // 方法正常结束，跳转到18返回13 astore_2 // 异常路径14 aload_1 // 入栈this，用于调用methodA15 monitorexit // 退出同步16 aload_2 // 异常对象入栈17 athrow // 抛出异常给调用者18 return // 方法结束 从上面了解到，synchronized修饰符在不同方法上以及同步构造器中传入的参数不同，监视的对象是不同的，大致分为以下几种情况： 实例方法 123456789synchronized void methodB()&#123; System.out.println("threadName = " + Thread.currentThread().getName() + " enter sync methodB."); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("threadName = " + Thread.currentThread().getName() + " leave sync methodB.");&#125; Java实例方法同步是同步在拥有该方法的对象上。这样，每个实例其方法同步都同步在不同的对象上，即该方法所属的实例对象。 静态方法 123456789synchronized static void methodA()&#123; System.out.println("threadName = " + Thread.currentThread().getName() + " enter sync static methodA."); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("threadName = " + Thread.currentThread().getName() + " leave sync static methodA.");&#125; 静态方法的同步是指同步在该方法所在的类对象上。因为在Java虚拟机中一个类只能对应一个类对象(即只能被一个ClassLoader加载)，所以同时只允许一个线程执行同一个类中的静态同步方法。 实例方法中的同步块 123456789101112void methodA() &#123; System.out.println("methodA time = " + System.currentTimeMillis()); synchronized (this)&#123; System.out.println("methodA begin time = " + System.currentTimeMillis()); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("methodA end time = " + System.currentTimeMillis()); &#125;&#125; 在同步构造器中用括号括起来的对象叫做监视器对象。同时只有一个线程能够在同步于同一个监视器对象的Java方法内执行。 静态方法中的同步块 123456789101112131415161718192021222324private static class InStaticMethodSync&#123; public static void methodA()&#123; synchronized(InStaticMethodSync.class)&#123; System.out.println("methodA begin time = " + System.currentTimeMillis()); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println("methodA begin time = " + System.currentTimeMillis()); &#125; public static void methodB()&#123; synchronized(InStaticMethodSync.class)&#123; System.out.println("methodB begin time = " + System.currentTimeMillis()); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println("methodB begin time = " + System.currentTimeMillis()); &#125;&#125; 这个地方同步构造器中是InStaticMethodSync.class，那么这里监视的就是class对象，因此InStaticMethodSync.class的其它被synchronized修饰的静态方法与该同步块同时只有一个线程能够执行。 摘抄自《深入理解Java虚拟机：JVM高级特性与最佳实践（第二版）》 根据虚拟机规范的要求，在执行monitorenter指令时，首先要尝试获取对象的锁。如果这个对象没被锁定，或者当前线程已经拥有了那个对象的锁，把锁的计数器加1，相应的，在执行monitorexit指令时会将锁计数器减1，当计数器为0时，锁就被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到对象锁被另外一个线程释放为止。 在虚拟机规范对monitorenter和monitorexit的行为描述中，有两点是需要特别注意的。首先，synchronized同步块对同一条线程来说是可重入的，不会出现自己把自己锁死的问题。其次，同步块在已进入的线程执行完之前，会阻塞后面其他线程的进入。Java的线程是映射到操作系统的原生线程之上的，如果要阻塞或唤醒一个线程，都需要操作系统来帮忙完成，这就需要从用户态转换到核心态中，因此状态转换需要耗费很多的处理器时间。对于代码简单的同步块（如被synchronized修饰的getter()或setter()方法），状态转换消耗的时间有可能比用户代码执行的时间还要长。所以synchronized是Java语言中一个重量级（Heavyweight）的操作，有经验的程序员都会在确实必要的情况下才使用这种操作。而虚拟机本身也会进行一些优化，譬如在通知操作系统阻塞线程之前加入一段自旋等待过程，避免频繁地切入到核心态之中。 ¶Lock synchronized同步块一样，是一种线程同步机制，但比Java中的synchronized同步块更复杂。 自Java 5开始，java.util.concurrent.locks包中包含了一些锁的实现，因此我们不用去实现自己的锁了。但是我们仍然需要去了解怎样使用这些锁，且了解这些实现背后的理论也是很有用处的。 ¶锁的使用 以之前的代码为例，使用Lock代替synchronized达到了同样的目的 ： 123456789101112131415161718192021222324252627282930private Lock lock = new ReentrantLock();/** 实例变量非线程安全的 */private int instanceNum;private void addInstanceNum(String username)&#123; try &#123; lock.lock(); if("b".equals(username))&#123; instanceNum = 200; System.out.println("b set over!"); &#125;else&#123; instanceNum = 100; System.out.println("a set over!"); Thread.sleep(2000); &#125; System.out.println(username + " num = " + instanceNum); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125;&#125;@Testpublic void threadSetInstanceNumTest() throws InterruptedException &#123; Thread threadA = new Thread(()-&gt;addInstanceNum("a")); Thread threadB = new Thread(()-&gt;addInstanceNum("b")); threadA.start(); threadB.start(); Thread.sleep(3000);&#125; lock()方法会对Lock实例对象进行加锁，因此所有对该对象调用lock()方法的线程都会被阻塞，直到该Lock对象的unlock()方法被调用。 ¶锁的简单实现 1234567891011121314public class SimpleLock&#123; private boolean isLocked = false; public synchronized void lock() throws InterruptedException&#123; while(isLocked)&#123; wait(); &#125; isLocked = true; &#125; public synchronized void unlock()&#123; isLocked = false; notify(); &#125;&#125; 注意其中的while(isLocked)循环，它又被叫做“自旋锁”。自旋锁以及wait()和notify()方法在线程通信这篇文章中有更加详细的介绍。当isLocked为true时，调用lock()的线程在wait()调用上阻塞等待。为防止该线程没有收到notify()调用也从wait()中返回（也称作虚假唤醒），这个线程会重新去检查isLocked条件以决定当前是否可以安全地继续执行还是需要重新保持等待，而不是认为线程被唤醒了就可以安全地继续执行了。如果isLocked为false，当前线程会退出while(isLocked)循环，并将isLocked设回true，让其它正在调用lock()方法的线程能够在Lock实例上加锁。 当线程完成了临界区（位于lock()和unlock()之间）中的代码，就会调用unlock()。执行unlock()会重新将isLocked设置为false，并且通知（唤醒）其中一个（若有的话）在lock()方法中调用了wait()函数而处于等待状态的线程。 java中的锁ReentrantLock不是基于synchronized而是基于原子类实现的，其核心代码如下： 1234567891011121314151617181920212223242526272829303132333435final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1);&#125;// 第一步compareAndSetState失败时，表示已经有线程获取到锁了，那么调用acquire请求锁public final void acquire(int arg) &#123; // 先尝试一下，能否请求到锁，不能请求到锁的话，开始排队请求锁(排队的请求者存放在链表中) if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125;final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; // 这里有个死循环，知道请求到锁，其实也就是CAS for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; ¶可重入性 Java中的synchronized同步块是可重入的，使用以下代码来进行分析： 12345678910111213141516171819202122static class ReentrantSyncMethodTest&#123; synchronized void methodA()&#123; System.out.println("methodA"); methodB(); &#125; synchronized void methodB()&#123; System.out.println("methodB"); &#125;&#125;@Test/** * 可重入锁：自己可以再次获取自己的内部锁 * * 如果不可重入的话 * 线程进入methodA获取了该对象的锁，然后执行methodB还是需要获取该对象的锁， * 但是methodA还没有执行完不会将锁释放，就会造成死锁。 */public void reentrantSyncMethodTest()&#123; ReentrantSyncMethodTest reentrantSyncMethodTest = new ReentrantSyncMethodTest(); Thread thread = new Thread(()-&gt; reentrantSyncMethodTest.methodA()); thread.start();&#125; 到这里想一想，我们之前的SimpleLock是否是可重入锁，很明显它不是，获取锁的条件是：只有当isLocked为false时lock操作才被允许，而没有考虑是哪个线程锁住了它。 为了让SimpleLock具有可重入性，我们只需要对其进行简单修改即可： 12345678910111213141516171819202122232425262728public class SimpleReentrantLock&#123; boolean isLocked = false; Thread lockedBy = null; int lockedCount = 0; public synchronized void lock() throws InterruptedException&#123; Thread callingThread = Thread.currentThread(); while(isLocked &amp;&amp; lockedBy != callingThread)&#123; wait(); &#125; isLocked = true; lockedCount++; lockedBy = callingThread; &#125; public synchronized void unlock()&#123; if(Thread.currentThread() == this.lockedBy)&#123; lockedCount--; if(lockedCount == 0)&#123; isLocked = false; notify(); &#125; &#125; &#125;&#125; 注意到现在的while循环（自旋锁）也考虑到了已锁住该Lock实例的线程。如果当前的锁对象没有被加锁(isLocked = false)，或者当前调用线程已经对该Lock实例加了锁，那么while循环就不会被执行，调用lock()的线程就可以退出该方法。 除此之外，我们需要记录同一个线程重复对一个锁对象加锁的次数。否则，一次unblock()调用就会解除整个锁，即使当前锁已经被加锁过多次。在unlock()调用没有达到对应lock()调用的次数之前，我们不希望锁被解除。 现在这个Lock类就是可重入的了。 java中的ReentrantLock实现方式与SimpleReentrantLock实现方式大同小异： 1234567891011121314151617181920final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); // 当前状态为1的话，就表示已经有线程获取到锁了 if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; // 如果持有锁的线程是当前线程的话，直接返回true，表示已经请求到锁了，可重入行也就体现在这里 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false;&#125; ¶公平性 Java的synchronized块并不保证尝试进入它们的线程的顺序。因此，如果多个线程不断竞争访问相同的synchronized同步块，就存在一种风险，其中一个或多个线程永远也得不到访问权 —— 也就是说访问权总是分配给了其它线程。这种情况被称作线程饥饿。为了避免这种问题，锁需要实现公平性。本文所展现的锁在内部是用synchronized同步块实现的，因此它们也不保证公平性。 ReentrantLock、ReentrantReadWriteLock可以通过构造函数指定是否为公平锁，其核心代码如下： 123456789101112131415161718192021222324252627282930313233343536// 默认实现final boolean nonfairTryAcquire(int acquires) &#123; ··· // 当有一个线程将锁释放了，这里的状态就为0了 if (c == 0) &#123; // 这里所有的等待线程都会进行这个CAS操作，谁能抢到就看运气了，所以是不公平的 if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; ···&#125;// 公平锁的实现final boolean tryAcquire(int acquires) &#123; ··· // 当有一个线程将锁释放了，这里的状态就为0了 if (c == 0) &#123; // 这里进行CAS之前会判断一下，是否是排在链表最前端的线程，如果是则进行CAS操作，所以是公平的 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; ···&#125;public final boolean hasQueuedPredecessors() &#123; Node t = tail; Node h = head; Node s; // 1、h == t 表示只有一个等待线程，直接获取锁即可 // 2、h.next == null 表示只有一个等待线程，直接获取锁即可 // 3、s.thread != Thread.currentThread() 排在链表最前端的不是当前线程，那么继续进入等待，知道当前线程排在最前端 return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread());&#125; ¶读写锁 读锁的获取条件：没有线程拥有写锁（writers==0），且没有线程在请求写锁（writeRequests ==0） 写锁的获取条件：当一个线程想获得写锁的时候，首先会把写锁请求数加1（writeRequests++），然后再去判断是否能够真能获得写锁，当没有线程持有读锁（readers==0 ）,且没有线程持有写锁（writers==0）时就能获得写锁。有多少线程在请求写锁并无关系。 ¶非阻塞同步–乐观锁 摘抄自《深入理解Java虚拟机：JVM高级特性与最佳实践（第二版）》 互斥同步最主要的问题就是进行线程阻塞和唤醒所带来的性能问题，因此这种同步也称为阻塞同步（Blocking Synchronization）。随着硬件指令集的发展，我们有了另外一个选择：基于冲突检测的乐观并发策略，通俗地说，就是先进行操作，如果没有其他线程争用共享数据，那操作就成功了；如果共享数据有争用，产生了冲突，那就再采取其他的补偿措施（最常见的补偿措施就是不断地重试，直到成功为止），这种乐观的并发策略的许多实现都不需要把线程挂起，因此这种同步操作称为非阻塞同步（Non-Blocking Synchronization）。 为什么笔者说使用乐观并发策略需要“硬件指令集的发展”才能进行呢？因为我们需要操作和冲突检测这两个步骤具备原子性，靠什么来保证呢？如果这里再使用互斥同步来保证就失去意义了，所以我们只能靠硬件来完成这件事情，硬件保证一个从语义上看起来需要多次操作的行为只通过一条处理器指令就能完成，这类指令常用的有： 测试并设置（Test-and-Set）。 获取并增加（Fetch-and-Increment）。 交换（Swap）。 比较并交换（Compare-and-Swap，下文称CAS）。 加载链接/条件存储（Load-Linked/Store-Conditional，下文称LL/SC）。 其中，前面的3条是20世纪就已经存在于大多数指令集之中的处理器指令，后面的两条是现代处理器新增的，而且这两条指令的目的和功能是类似的。在IA64、x86指令集中有cmpxchg指令完成CAS功能，在sparc-TSO也有casa指令实现，而在ARM和PowerPC架构下，则需要使用一对ldrex/strex指令来完成LL/SC的功能。 CAS指令需要有3个操作数，分别是内存位置（在Java中可以简单理解为变量的内存地址，用V表示）、旧的预期值（用A表示）和新值（用B表示）。CAS指令执行时，当且仅当V符合旧预期值A时，处理器用新值B更新V的值，否则它就不执行更新，但是无论是否更新了V的值，都会返回V的旧值，上述的处理过程是一个原子操作。 java中AtomicInteger的自增实现如下： 12345678public final int incrementAndGet() &#123; for (;;) &#123; int current = get(); int next = current + 1; if (compareAndSet(current, next)) return next; &#125;&#125; JDK1.8起，Unsafe提供了compareAndSwapInt方法底层由C实现，直接实现了CAS操作： 123public final boolean compareAndSet(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, valueOffset, expect, update);&#125; CAS操作有个逻辑漏洞：如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然为A值，那我们就能说它的值没有被其他线程改变过了吗？如果在这段期间它的值曾经被改成了B，后来又被改回为A，那CAS操作就会误认为它从来没有被改变过。这个漏洞称为CAS操作的“ABA”问题。J.U.C包为了解决这个问题，提供了一个带有标记的原子引用类“AtomicStampedReference”，它可以通过控制变量值的版本来保证CAS的正确性。不过目前来说这个类比较“鸡肋”，大部分情况下ABA问题不会影响程序并发的正确性，如果需要解决ABA问题，改用传统的互斥同步可能会比原子类更高效。 ¶无同步方案 保证线程安全，并不是一定要进行同步的，两者没有因果关系。如果方法不涉及共享数据，那么它也不需要进行同步了。 可重入代码 不依赖存储在堆上的数据和共用的资源 在入参相同的情况，执行结果都是相同的 线程本地存储 共享数据的代码放到同一个线程执行 ThreadLocal ¶锁优化 ¶自旋锁与自适应自旋 互斥同步对性能最大的影响是阻塞的实现，挂起线程和恢复线程的操作都需要转入内核态中完成，这些操作给系统的并发性能带来了很大的压力。同时，虚拟机的开发团队也注意到在许多应用上，共享数据的锁定状态只会持续很短的一段时间，为了这段时间去挂起和恢复线程并不值得。如果物理机器有一个以上的处理器，能让两个或以上的线程同时并行执行，我们就可以让后面请求锁的那个线程“稍等一下”，但不放弃处理器的执行时间，看看持有锁的线程是否很快就会释放锁。为了让线程等待，我们只需让线程执行一个忙循环（自旋），这项技术就是所谓的自旋锁。 自旋等待本身虽然避免了线程切换的开销，但它是要占用处理器时间的，因此，如果锁被占用的时间很短，自旋等待的效果就会非常好，反之，如果锁被占用的时间很长，那么自旋的线程只会白白消耗处理器资源，而不会做任何有用的工作，反而会带来性能上的浪费。因此，自旋等待的时间必须要有一定的限度，如果自旋超过了限定的次数仍然没有成功获得锁，就应当使用传统的方式去挂起线程了。自旋次数的默认值是10次，用户可以使用参数-XX:PreBlockSpin来更改。 在JDK 1.6中引入了自适应的自旋锁。自适应意味着自旋的时间不再固定了，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也很有可能再次成功，进而它将允许自旋等待持续相对更长的时间，比如100个循环。另外，如果对于某个锁，自旋很少成功获得过，那在以后要获取这个锁时将可能省略掉自旋过程，以避免浪费处理器资源。有了自适应自旋，随着程序运行和性能监控信息的不断完善，虚拟机对程序锁的状况预测就会越来越准确，虚拟机就会变得越来越“聪明”了。 ¶锁消除 锁消除是指虚拟机即时编译器在运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除。锁消除的主要判定依据来源于逃逸分析的数据支持，如果判断在一段代码中，堆上的所有数据都不会逃逸出去从而被其他线程访问到，那就可以把它们当做栈上数据对待，认为它们是线程私有的，同步加锁自然就无须进行。 ¶锁粗化 原则上，我们在编写代码的时候，总是推荐将同步块的作用范围限制得尽量小——只在共享数据的实际作用域中才进行同步，这样是为了使得需要同步的操作数量尽可能变小，如果存在锁竞争，那等待锁的线程也能尽快拿到锁。 大部分情况下，上面的原则都是正确的，但是如果一系列的连续操作都对同一个对象反复加锁和解锁，甚至加锁操作是出现在循环体中的，那即使没有线程竞争，频繁地进行互斥同步操作也会导致不必要的性能损耗。 ¶轻量级锁 “轻量级”是相对于使用操作系统互斥量来实现的传统锁而言的，因此传统的锁机制就称为“重量级”锁。首先需要强调一点的是，轻量级锁并不是用来代替重量级锁的，它的本意是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。 使用轻量级锁时，不需要申请互斥量，仅仅将Mark Word中的部分字节CAS更新指向线程栈中的Lock Record，如果更新成功，则轻量级锁获取成功，记录锁状态为轻量级锁；否则，说明已经有线程获得了轻量级锁，目前发生了锁竞争（不适合继续使用轻量级锁），接下来膨胀为重量级锁。 Mark Word是对象头的一部分；每个线程都拥有自己的线程栈（虚拟机栈），记录线程和函数调用的基本信息。 ¶偏向锁 “偏向”的意思是，偏向锁假定将来只有第一个申请锁的线程会使用锁（不会有任何线程再来申请锁），因此，只需要在Mark Word中CAS记录owner（本质上也是更新，但初始值为空），如果记录成功，则偏向锁获取成功，记录锁状态为偏向锁，以后当前线程等于owner就可以零成本的直接获得锁；否则，说明有其他线程竞争，膨胀为轻量级锁。 偏向锁无法使用自旋锁优化，因为一旦有其他线程申请锁，就破坏了偏向锁的假定。 参考文献 并发编程网–Java并发性和多线程介绍 《深入理解Java虚拟机：JVM高级特性与最佳实践（第二版）》]]></content>
      <categories>
        <category>java多线程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>java多线程</tag>
        <tag>多线程编程</tag>
        <tag>lock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程与线程安全]]></title>
    <url>%2Fmutlithreading%2Fmutlithreading.html</url>
    <content type="text"><![CDATA[《Java Concurrency In Practice》的作者Brian Goetz对“线程安全”有一个比较恰当的定义：“当多个线程访问一个对象时，如果不用考虑这些线程在运行时环境下的调度和交替执行，也不需要进行额外的同步，或者在调用方进行任何其他的协调操作，调用这个对象的行为都可以获得正确的结果，那这个对象是线程安全的”。 转载自姜函的：多线程与线程安全 ¶多线程与线程安全 ¶Java内存模型 ¶线程不安全的源头 ¶CPU、内存、I/O的恩怨情仇 这些年，我们的 CPU、内存、I/O 设备都在不断迭代，不断朝着更快的方向努力。但是，在这个快速发展的过程中，有一个核心矛盾一直存在，就是这三者的速度差异。我们都知道就速度而言，CPU&gt;&gt;内存&gt;&gt;I/O设备，所以为了平衡这三者之间的速度差异，计算机体系机构、操作系统、编译程序都做出了贡献，主要体现为： CPU 增加了缓存，以均衡与内存的速度差异 操作系统增加了进程、线程，以分时复用 CPU，进而均衡 CPU 与 I/O 设备的速度差异 编译程序优化指令执行次序，使得缓存能够得到更加合理地利用 但是，是的，凡事都有但是，这些优化让我们享受的同时，也带来了线程不安全的问题。 ¶源头之一：缓存导致的可见性 多核时代，每颗 CPU 都有自己的缓存，当多个线程在不同的 CPU 上执行时，这些线程操作的是不同的 CPU 缓存。比如下图中，线程 A 操作的是 CPU-1 上的缓存，而线程 B 操作的是 CPU-2 上的缓存，很明显，这个时候线程 A 对变量 V 的操作对于线程 B 而言就不具备可见性了。这个就属于硬件程序员给软件程序员挖的“坑”。 ¶源头之二：线程切换带来的原子性问题 操作系统允许某个进程执行一小段时间，例如 50 毫秒，过了 50 毫秒操作系统就会重新选择一个进程来执行（我们称为“任务切换”），这个 50 毫秒称为“时间片“。现代的操作系统都基于更轻量的线程来调度，现在我们提到的“任务切换”都是指“线程切换”。Java 并发程序都是基于多线程的，自然也会涉及到任务切换，也许你想不到，任务切换竟然也是并发编程里诡异 Bug 的源头之一。任务切换的时机大多数是在时间片结束的时候，我们现在基本都使用高级语言编程，高级语言里一条语句往往需要多条 CPU 指令完成，例如大家所熟悉的count++,这个语句需要3条指令才能执行： 指令 1：首先，需要把变量 count 从内存加载到 CPU 的寄存器 指令 2：之后，在寄存器中执行 +1 操作 指令 3：最后，将结果写入内存（缓存机制导致可能写入的是 CPU 缓存而不是内存） 操作系统做任务切换，可以发生在任何一条CPU指令。对于上面的三条指令来说，我们假设 count=0，如果线程 A 在指令 1 执行完后做线程切换，线程 A 和线程 B 按照下图的序列执行，那么我们会发现两个线程都执行了 count+=1 的操作，但是得到的结果不是我们期望的 2，而是 1。 ¶源头之三：编译优化带来的有序性问题 有序性，顾名思义，有序性指的是程序按照代码的先后顺序执行。编译器为了优化性能，有时候会改变程序中语句的先后顺序，例如程序中：“a=6；b=7；”编译器优化后可能变成“b=7；a=6；”，在这个例子中，编译器调整了语句的顺序，但是不影响程序的最终结果。不过有时候编译器及解释器的优化可能导致意想不到的 Bug。再次拿出这个臭名昭著的DCL单例模式来举栗子： 12345678910111213141516public class Singleton &#123; static Singleton instance; static Singleton getInstance()&#123; if (instance == null) &#123; synchronized(Singleton.class) &#123; if (instance == null) instance = new Singleton(); &#125; &#125; return instance; &#125; &#125; 这个创建单例的模式为什么在多线程的情况下会出问题呢？主要是在new Singleton()这一步上，我们凭直觉以为这个new操作是这样的： 分配一块内存 M 在内存 M 上初始化 Singleton对象 然后 M 的地址赋值给 instance 变量 实际上优化后的执行顺序长这样： 分配一块内存 M 将 M 的地址赋值给 instance 变量 最后在内存 M 上初始化 Singleton 对象 所以这种情况下当A线程执行这个new操作的时候，这个时候M的地址已经赋给instance 变量，但是还未初始化，这时另外一个线程B同时进入getInstance()方法，检测到instance不为null，直接返回，而返回的是一个无效值，会触发空指针异常。 ¶Java内存模型的概念 Java虚拟机规范中试图定义一种Java内存模型来屏蔽掉各种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的并发效果。Java内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节，此处的变量与Java编程中所说的变量略有区别，它包括了实例字段、静态字段和构成数组对象的元素， 但是不包括局部变量与方法参数，因为后者是线程私有的，不会被共享，自然就不存在竟争问题。 Java内存模型规定了所有的变量都存储在主内存上，每条线程还有自己的工作内存，线程的工作内存中保存了被该线程使用到的变量的主内存副本拷贝，线程对变量的所有操作(读取、赋值等)都必须在工作内存中进行，而不能直接读写主内存中的变量。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递都需要通过主内存来传递，线程、主内存、工作内存的交互关系如下。 JDK在1.5之后对Java内存模型做了很大的修正，我们接下来的讨论也是基于JDK1.5之后的Java内存模型。 ¶Happens-Before happens—before规则是Java内存模型中定义的两项操作之间的偏序关系，如果操作A先行发生于操作B，其意思就是说，在发生操作B之前，操作A产生的影响都能被操作B观察到，“影响”包括修改了内存中共享变量的值、发送了消息、调用了方法等，它与时间上的先后发生基本没有太大关系。这个原则特别重要，它是判断数据是否存在竞争、线程是否安全的主要依据。具体包括： 程序次序规则：在一个单独的线程中，按照程序代码的执行流顺序，（时间上）先执行的操作happen—before（时间上）后执行的操作 管程锁定规则：一个unlock操作happen—before后面（时间上的先后顺序，下同）对同一个锁的lock操作 volatile变量规则：对一个volatile变量的写操作happen—before后面对该变量的读操作 线程启动规则：Thread对象的start（）方法happen—before此线程的每一个动作 线程终止规则：线程的所有操作都happen—before对此线程的终止检测，可以通过Thread.join（）方法结束或者Thread.isAlive（）的返回值等手段检测到线程已经终止执行 线程中断规则：对线程interrupt（）方法的调用happen—before发生于被中断线程的代码检测到中断时事件的发生 对象终结规则：一个对象的初始化完成（构造函数执行结束）happen—before它的finalize（）方法的开始 传递性：如果操作A happen—before操作B，操作B happen—before操作C，那么可以得出A happen—before操作C 这是Java中仅有的无须任何同步手段就可以保证先行发生规则，我们可以通过一个简单的getter/setter示例感受一下“先行发生”与”时间上的先后发生“有何区别： 123456789private int value = 0;public int getValue()&#123; return value;&#125;public void setValue(int value)&#123; this.value = value;&#125; 假设线程A先调用setValue(10)，然后线程B再去调用同一个对象的getValue，那么线程B收到的值是10吗？我们可以根据上述的规则进行分析，没有一个规则适用，也就是说无法保证这两个操作的先行发生关系，所以线程B获得的结果是不确定的，换句话说这是线程不安全的。而让他变得线程安全也至少有两种简单的方案： 给get/set方法加锁，这样就可以套用管程锁定规则 让value定义为volatile变量，这样就能套用volatile变量规则 ¶最轻量级的同步机制volatile 当一个变量为定义为volatile之后，将具备两个特性： 可见性：这里的可见是指当一个线程修改了变量的值，其他线程可以立即看见。但是请注意，volatile可以保证并发情况下变量在各个线程中保证一致性，但是并不能说在并发条件下是线程安全的，因为volatile并不能保证原子性，我们可以用一个示例的来说明： 1234567891011121314151617181920212223242526272829public class VolatileTest &#123; public static volatile int race = 0; public static void increase()&#123; race++; &#125; private static final int THREAD_COUNT = 20; public static void main(String[] args)&#123; for (int i = 0;i&lt;THREAD_COUNT;i++)&#123; new Thread( () -&gt; &#123; for (int j = 0;j&lt;10000;j++)&#123; increase(); &#125; &#125; ).start(); &#125; //等待所有累加线程都结束 while (Thread.activeCount()&gt;1)&#123; Thread.yield(); &#125; System.out.println(race); &#125;&#125; 代码发起了20个线程，每个线程对race变量进行10000次更新，如果正确并发结果应该是200000。但是实际上每次的输出结果都不一样，都是一个小于200000的数。这是由于incerese（）方法实际上由4条字节码组成，当getstatic指令将操作数取到栈顶时，race的值上正确的，但是执行icont_1,iadd指令的时候其他线程可能已经改变了race的值，在执行putstatic的时候就不再正确了。 12345678910public static void increase()&#123; Code: Stack = 2,Local = 0,Args_size = 0; 0: getstatic 3:iconst_1 4:add 5:putstatic 8:return &#125; volatile非常适合用作某个操作完成、发生中断或者状态的标志,如下图，调用shutdown方法后，所有线程会停止工作： 123456789101112volatile boolean requested;public void shutdown()&#123; requested = true;&#125;public viod doWork()&#123; while(!requested)&#123; // do something &#125;&#125; volatile的第二个作用是特性是禁止指令重排序，volatile变量赋值后，会多执行一个“lock add1 $0X0”操作，这个操作相当于一个内存屏障，指令重排时不能把后面的指令重排序到内存屏障之前的位置。还是拿出我们上面那个DCL单例的模式来，这次我们使用volatile变量后，就可以正确的实现单例模式： 1234567891011121314151617public class Singleton &#123; static volatile Singleton instance; static Singleton getInstance()&#123; if (instance == null) &#123; synchronized(Singleton.class) &#123; if (instance == null) // 由于是volatile变量，此处不会进行重排序 instance = new Singleton(); &#125; &#125; return instance; &#125; &#125; 通过上述的情况我们大概了解了volatile的基本特性，也知道了volatile是一个轻量级的同步机制，在某些情况下，volatile的性能会优于锁的性能，但是经过虚拟机对锁的优化和消除后，并不能量化的认为volatile就比synchronized快多少，所以我们选择volatile的唯一依据应该是它能否满足我们的应用需求，总结一下，当且仅当以下条件满足时，应该使用volatile变量： 对变量的写入不依赖变量的当前值，或者能确保只有单个线程更新变量的值； 改变量不会与其他状态变量一起纳入不变性条件中； 访问变量时不需要加锁 ¶Java与线程 ¶线程的实现 实现线程主要有三种方式:使用内核线程实现，使用用户线程实现，使用用户线程加轻量级进程混合实现。 ¶1.使用内核线程实现 内核线程（Kernel Thread, KLT）就是直接由操作系统内核（Kernel,下称内核）支持的线程，这种线程由内核来完成线程切换，内核通过操纵调度器（Scheduler）对线程进行调度，并负责将线程的任务映射到各个处理器上。每个内核线程都可以看做是内核的一个分身，这样操作系统就有能力同时处理多件事情，支持多线程的内核就叫多线程内核(Multi-Threads Kernel)。程序一般不会直接去使用内核线程，而是去使用内核线程的种高级接口–轻量级进程(Light Weight Process, LWP),轻量级进程就是我们通常意义上所讲的线程，由于每个轻量级进程都由一个内核线程支持，因此只有先支持内核线程，才能有轻量级进程。这种轻量级进程与内核线程之间1:1的关系称为一对一的线程模型。如图所示: 由于内核线程的支持，每个轻量级进程都成为一个独立的调度单元，即使有一个轻量级进程在系统调用中阻塞了，也不会影响整个进程继续工作，但是轻量级进程具有它的局限性:首先，由于是基于内核线程实现的，所以各种进程操作，如创建、析构及同步，都需要进行系统调用。而系统调用的代价相对较高，需要在用户态(User Mode )和内核态(Kernel Mode)中来回切换其次，每个轻量级进程都需要有一个内核线程的支持，因此轻量级进程要消耗一定的内核资源(如内核线程的栈空间)，因此一个系统支持轻量级进程的数量是有限的。 ¶2.使用用户线程实现 广义上来讲，一个线程只要不是内核线程，那就可以认为是用户线程（UserThread, UT ) ,因此从这个定义上来讲轻最级进程也属于用户线程，但轻量级进程的实现始终是建立在内核之上的，许多操作都要进行系统调用，因此效率会受到限制。 而狭义上的用户线程指的是完全建众在用户空间的线程库上，系统内核不能感知到线程存在的实现。用户线程的建立、同步、销毁和调度完全在用户态中完成，不需要内核的帮助。如果程序实现得当，这种线程不需要切换到内核态，因此操作可以是非常快速且低消耗的，也可以支持规模更大的线程数量，部分高性能数据库中的多线程就是由用户线程实现的。这种进程与用户线程之间1:N的关系称为一对多的线程模型，如图所示。 使用用户线程的优势在于不需要系统内核支援，劣势也在于没有系统内核的支援，所有的线程操作都需要用户程序自己处理，而线程的创建、切换和调度都是需要考虑问题，而且由于操作系统只把处理器资源分配到进程，那诸如“阻塞如何处理”、“多处理器系统中如何将线程映射到其他处理器上”这类问题解决起来将会异常困难，甚至不可能完成。因而使用用户线程实现的程序一般都比较复杂，除了以前在不支持多线程的操作系统中(如Dos)的多线程程序与少数有特殊需求的程序外，现在使用用户线程的程序越来越少了，Java, Ruby等语言都曾经使用过用户线程，最终又都放弃了 使用它。 ¶3.混合实现 线程除了依赖内核线程实现和完全由用户程序自己实现之外，还有一种将内核线程与用户线程一起使用的实现方式。在这种混合实现下，既存在用户线程，也存在轻量级进程。用户线程还是完全建立在用户空间中，因此用户线程的创建、切换、析构等操作依然廉价，并且可以支持大规模的用户线程并发。而操作系统提供支持的轻量级进程则作为用户线程和内核线程之间的桥梁，这样可以使用内核提供的线程调度功能及处理器映射。井且用户线程的系统调用要通过轻量级线程来完成，大大降低了进程被阻塞的风险。在这种混合模式中，用户线程与轻量级进程的数量比是不的，是M:N的关系，如图所示，这种就是多对多的线程模型。 ¶4.Java线程的实现 Java线程在JDK1.2之前，是基于名为“绿色线程&quot; (Green Threads)的用户线程实现的，而在JDK l .2中，线程模型被替换为基于操作系统原生线程模型来实现。因此在目前的JDIC版本中，操作系统支持怎样的线程模型，在很大程度上就决定了Java虚拟机的线程是怎样映射的，这点在不同的平台上没有办法达成一致，虚拟机规范中也并未限定Java线程需要使用哪种线程模型来实现。线程模型只对线程的并发规模和操作成本产生影响，对Java程序的编码和运行过程来说，这些差异都是透明的。对于Sun JDK来说，它的Windows版与Linux版都是使用一对一的线程模型来实现的，一条Java线程就映射到一条轻量级进程之中，因为Windows和Linux系统提供的线程模型就是一对一的。 ¶线程的调度 线程调度是指系统为线程分配处理器使用权的过程，主要调度方式有两种。分别是协程式(Cooperative Threads-Scheduling)线程调度和抢占式(Preemptive Threads-Scheduling)线程调度。 ¶协程式线程调度 如果使用协同式调度的多线程系统，线程的执行时间由线程本身来控制，线程把自己的工作执行完了之后，要主动通知系统切换到另外一个线程上去。协同式多线程的最大好处是实现简单，而且由于线程要把白己的事情干完后才会进行线程切换，切换操作对线程自己是可知的，所以没有什么线程同步的问题。它的坏处也很明显:线程执行时间不可控制，甚至如果一个线程编写有问题，一直不告知系统进行线程切换，那么程序就会一直阻塞在那里。很久以前的Windows 3.x系统就是使用协同式来实现多进程多任务的，那是相当的不稳定，一个进程坚持不让出CPU执行时间就会导致整个系统的崩溃。 ¶抢占式线程调度 如果使用抢占式调度的多线程系统，那么每个线程将由系统来分配执行时间，线程的切换不由线程本身来决定(在Java中，Thread.yield()可以让出执行时间，但是要获取执行时间的话，线程本身是没有什么办法的)。在这种实现线程调度的方式下，线程的执行时间是系统可控的，也不会有一个线程导致整个进程阻塞的问题，Java使用的线程调度方式就是抢占式调度。 虽然说Java线程调度是系统自动完成的，但是我们还是可以“建议”系统给某些线程多分配一点执行时间，另外的此线程则可以少分配一点。这项操作可以通过设置线程优先级来完成。Java语言一共设置了10个级别的线程优先级，在两个线程同时处于Ready状态时，优先级越高的线程越容易被系统选择执行。但是这种方法并不靠谱，因为Java的线程上被映射到系统的原生线程上实现的，所以最终线程调度还是由操作系统说了算，而不同操作系统的线程优先级不能保证与Java中的线程优先级一 一对应，同时有些操作系统如“Windows”存在一个“线程推进器”，它的大致作用是发现线程运行的特别“勤奋”，会越过线程优先级为线程分配时间。 ¶线程状态 Java中的线程一共有六种状态： NEW（初始化状态） RUNNABLE（可运行 / 运行状态） BLOCKED（阻塞状态） WAITING（无时限等待） TIMED_WAITING（有时限等待） TERMINATED（终止状态） 线程可以在这六种状态之间相互转换，如图所示： ¶从 NEW 到 RUNNABLE 状态 每个线程刚被创建的时候都是出于new状态，而要转换到RUNNABEL状态很简单，调用线程的start方法即可。 ¶RUNNABLE 与 BLOCKED 的状态转换 只有一种场景会触发这种转换: 就是线程等待 synchronized 的隐式锁。synchronized 修饰的方法、代码块同一时刻只允许一个线程执行，其他线程只能等待，这种情况下，等待的线程就会从 RUNNABLE 转换到 BLOCKED 状态。而当等待的线程获得 synchronized 隐式锁时，就又会从 BLOCKED 转换到 RUNNABLE 状态。 ¶RUNNABLE 与 WAITING 的状态转换 总的来说，有三种场景会触发这种改变 第一种场景，获得 synchronized 隐式锁的线程，调用无参数的 Object.wait() 方法。 第二种场景，调用无参数的 Thread.join() 方法。其中的 join() 是一种线程同步方法，例如有一个线程对象 thread A，当调用 A.join() 的时候，执行这条语句的线程会等待 thread A 执行完，而等待中的这个线程，其状态会从 RUNNABLE 转换到 WAITING。当线程 thread A 执行完，原来等待它的线程又会从 WAITING 状态转换到 RUNNABLE。 第三种场景，调用 LockSupport.park() 方法。其中的 LockSupport 对象，也许大家有点陌生，其实 Java 并发包中的锁，都是基于它实现的。调用 LockSupport.park() 方法，当前线程会阻塞，线程的状态会从 RUNNABLE 转换到 WAITING。调用 LockSupport.unpark(Thread thread) 可唤醒目标线程，目标线程的状态又会从 WAITING 状态转换到 RUNNABLE。 ¶RUNNABLE 与 TIMED_WAITING 的状态转换 有五种场景会触发这种转换： 调用带超时参数的 Thread.sleep(long millis) 方法； 获得 synchronized 隐式锁的线程，调用带超时参数的 Object.wait(long timeout) 方法； 调用带超时参数的 Thread.join(long millis) 方法； 调用带超时参数的 LockSupport.parkNanos(Object blocker, long deadline) 方法； 调用带超时参数的 LockSupport.parkUntil(long deadline) 方法。 这里你会发现 TIMED_WAITING 和 WAITING 状态的区别，仅仅是触发条件多了带超时参数. ¶从 RUNNABLE 到 TERMINATED 状态 线程执行完 run() 方法后，会自动转换到 TERMINATED 状态，当然如果执行 run() 方法的时候异常抛出，也会导致线程终止。有时候我们需要强制中断 run() 方法的执行，例如 run() 方法访问一个很慢的网络，我们等不下去了，想终止怎么办呢？Java 的 Thread 类里面倒是有个 stop() 方法，不过已经标记为 @Deprecated，所以不建议使用了。正确的姿势其实是调用 interrupt() 方法。 ¶线程安全 ¶Java语言的线程安全 什么是线程安全？《Java Concurrency In Practice》的作者Brian Goetz对“线程安全”有一个比较恰当的定义: 当多个线程访问一个对象时，如果不用考虑这些线程在运行时环境下的调度和交替执行，也不需要进行额外的同步，或者在调用方进行任何其他的协调操作，调用这个对象的行为都可以获得正确的结果，那这个对象就是线程安全的。 已经有了线程安全的一个抽象定义，那接下来我们就讨论一下在Java语言中，线程安全具体是如何体现的以及有哪些操作是线程安全的。为了更深入理解线程安全，我们可以不把线程安全当做一个非真既假的二元排他概念，按照线程安全的“安全程度”由强到弱，我们把Java语言中各种操作共享的数据分为以下五类:不可变、绝对线程安全、相对线程安全、线程兼容和线程对立。 ¶1.不可变 在Java语言里不可变( Immutalaie)的对象一定是线程安全的，无论是对象的方法实现还是方法的调用者，都不需要再进行任何的线程安全保障措施，只要一个不可变的对象被正确地构建出来，那其外部的可见状态永远也不会改变，永远也不会看到它在多个线程之中处于不一致的状态。“不可变”带来的安全性是最简单最纯粹的。比如String类型就是一个经典的不可变对象，我们调用substring(),replace()等方法时都会返回一个新的字符串对象，而不会影响原来的值。保证对象行为不影响自己状态的途径有很多种，其中最简单的就是把对象中带有状态的变量都声明为final。这样在构造函数结束之后，它就是不可变的。 ¶2.绝对线程安全 绝对的线程安全完全满足Brian Goetz给出的线程安全的定义其实是很严格的，一个类要达到“不管运行时环境如何，调用者都不需要任何额外的同步措施”通常需要付出很大的，甚至是不切实际的代价。在Java API中标注自己是线程安全的类，大多数都不是绝对的线程安全。我们可以通过Java API中一个不是“绝对线程安全”的线程安全类来看看这里的“绝对”是什么意思。比如Vector是一个大家公认的线程安全类，但是这并不意味这调用他的时候不在需要任何同步手段了，比如下面这个栗子： 12345678910111213141516171819202122232425262728public class AbsoluteThreadSafeTest &#123; private static Vector&lt;Integer&gt; vector = new Vector&lt;&gt;(); public static void main(String[] args) &#123; while (true)&#123; for (int i = 0;i&lt;10;i++)&#123; vector.add(i); &#125; new Thread(()-&gt;&#123; for (int i=0;i&lt;vector.size();i++)&#123; vector.remove(i); &#125; &#125;).start(); new Thread(()-&gt;&#123; for (int i=0;i&lt;vector.size();i++)&#123; vector.get(i); &#125; &#125;).start(); //避免创建过多线程 while (Thread.activeCount()&gt;20); &#125; &#125;&#125; 虽然vector的get(),size()以及get()方法都是同步的，但是上面的代码仍然会抛出ArrayIndexOutOfBoundsException异常，我们仍然需要通过加锁的方式来保证这段代码的线程安全性。 ¶3.相对线程安全 相对的线程安全就是我们通常意义上所讲的线程安全，它需要保证对这个对象单独的操作是线程安全的，我们在调用的时候不需要做额外的保障措施，但是对于一些特定顺序的连续调用，就可能需要在调用端使用额外的同步手段来保证调用的正确性。上面的栗子就是相对线程安全的一个很明显的案例。在Java语言中，大部分的线程安全类都属于这种类型，例如Vector, HashTable, Collections的synchronicedCollectiont()方法包装的集合等。 ¶4.线程兼容 线程兼容是指对象本身并不是线程安全的，但是可以通过在调用端正确地使用同步手段来保证对象在并发环境中安全地使用，我们平常说一个类不是线程安全的，绝大多数指的都是这种情况。Java API中大部分的类都是线程兼容的，如与前面的Vector和HashTable相对应的集合类ArrayList和HashMap等。 ¶5.线程对立 线程对立是指无论使用何种同步手段，代码都无法再多线程情况下并发使用的代码。由于Java语言的代码天生具有多线程性，所以这种情况极少出现。而且线程对立的代码是有害的，应该避免。 一个线程对立的例子是Thread类的suspend()和resume()方法，如果有两个线程同时持有一个线程对象，一个尝试去中断线程，一个尝试去恢复线程，如果并发进行的话，无论调用时是否进行了同步，目标线程都是存在死锁风险的，如果suspend()中断的线程就是即将要执行resume()的那个线程，那就肯定要产生死锁了。也正是由于这个原因，这两个方法已经被JDK声明废弃(@Deprecated )了。常见的线程对立的操作还有System.setIn(). Sytem.setout()和System. runFinalizersOnExit()等。 ¶实现线程安全的方法 在了解了什么是线程安全后，我们接下来了解一些实现线程安全的方法。 ¶1.互斥同步 在Java里面，最基本的互斥同步手段就是synchronized关键字，synchronized关键字经过编译之后，会在同步块的前后分别形成monitorenter和monitorexit这两个字节码指令，这两个字节码都需要一个reference类型的参数来指明要锁定和解锁的对象。如果Java程序中的synchronized明确指定了对象参数，那就是这个对象的reference，如果没有明确指定，那就根据synchronised修饰的是实例方法还是类方法，去取对应的对象实例或Class对象来作为锁对象。 根据Java虚拟机的规范，在执行monitorenter指令时，首先会去尝试获取对象的锁。如果这个对象没被锁定，或者当前程序已经获取了该对象的锁，则锁的计数器加1。相应的，在执行monitorexit指令时，如果计数器减1，当计数器为0，则代表锁被释放。 在虚拟机规范对monitorenter和monitnrexit的行为描述中，有两点是需要特别注意的： 首先，synchronized同步块对同一条线程来说是可重入的，不会出现自己把自己锁死的问题。 其次，同步块在已进入的线程执行完之前。会阻塞后面其他线程的进入。我们讨论过，Java的线程是映射到操作系统的原生线程之上的，如果要阻塞或唤醒一条线程。都需要操作系统来帮忙完成，这就需要从用户态转换到核心态中，因此状态转换需要耗费很多的处理器时间。对于代码简单的同步块(如被synchronized修饰的gctter()或setter()方法)，状态转换消耗的时间可能比用户代码执行的时间还要长。所以synchronized语言中一个重量级(Heavyweight)的操作，有经验的程序员都会在确实必要的情况下才使用这种操作。而虚拟机本身也会进行一些优化，譬如在通知操作系统阻塞线程之前加人一段自旋等待过程，避免频繁地切人到核心态之中。 ¶2.非阻塞同步 互斥同步最主要的问题就是进行线程阻塞和唤醒所带来的性能问题，因此这种同步也被称为阻塞同步（Blocking Synchronization）,另外，它属于一种悲观的并发策略。总是认为只要不去做正确的同步措施（加锁)，那就肯定会出现问题，无论共享数据是否真的会出现竞争，它都要进行加锁(这里说的是概念模型。实际上虚拟机会优化掉很大一部分不必要的加锁)、用户态核心态转换、维护锁计数器和检查是否有被阻塞的线程需要被唤醒等操作。随着硬件指令集的发展，我们有了另外一个选择。基于冲突检测的乐观并发策略，通俗地说就是先进行操作，如果没有其他线程争用共享数据，那操作就成功了;如果共享数据有争用，产生了冲突，那就再进行共他的补偿措施(最常见的补偿措施就是不断地重试，直到试成功为止〕，这种乐观的并发策略的许多实现都不需要把线程挂起，因此这种同步操作被称为非阻塞同步(Non-Blocking Synchronization）。 能够帮助我们实现非阻塞同步的指令包括： 测试并设置（Test-And-Set） 获取并增加（Fetch-and-Increament） 交换（Swap) 比较并交换（Compare-and-Swap,CAS） 加载链接/条件存储（Load-Linked/Store-Conditional,LL/SC） 接下来我们重点讨论一下CAS指令。CAS指令需要有三个操作数，分别是内存位置(在Java中可以简单理解为变量的内存地址，用V表示)、旧的预期值(用A表示)和新值(用B表示)。CAS指令执 行时，当且仅当V符合旧预期值A时，处理器用新值S更新V的值，否则它就不执行更新，但是不管是否更新了V的值，都会返回V的旧值，上述的处理过程是一个原子操作。 我们可以通过Java API来间接使用Unsafe类中提供的CAS操作，比如AtomicInteger类中的incrementAndGet()，getAndAdd()等方法，我们可以用volatile无法保证原子操作的示例来演示一下CAS用来避免阻塞同步： 12345678910111213141516171819202122232425262728public class AtomicTest &#123; public static AtomicInteger race = new AtomicInteger(0); public static void increase()&#123; race.incrementAndGet(); &#125; private static final int THREAD_COUNT = 20; public static void main(String[] args)&#123; for (int i = 0;i&lt;THREAD_COUNT;i++)&#123; new Thread( () -&gt; &#123; for (int j = 0;j&lt;10000;j++)&#123; increase(); &#125; &#125; ).start(); &#125; while (Thread.activeCount()&gt;1)&#123; Thread.yield(); &#125; System.out.println(race); &#125;&#125; ¶3.无同步手段 要保证线程安全不一定需要同步，在Java中有些代码天生就是线程安全的，我们简单的来讨论一下常见的两类。 ¶可重入性的代码 这种代码也叫纯代码( Pure Code ），可以在代码执行的任何时刻中断它，转而去执行另外一段代码(包括递归调用它本身)，而在控制权返回后，原来的程序不会出现任何错误。相对线程安全来说，可重入性是更基本的特性，它可以保证线程安全，即所有的可重人的代码都是线程安全的，但是并非所有的线程安全的代码都是可重入的。 可重入代码有一些共同的特征:例如不依赖存储在堆上的数据和公用的系统资源、用到的状态量都由参数中传入、不调用非可重人的方法等。我们可以通过一个简单的原则来判断代码是否具备可重入性:如果一个方法，它的返回结果是可以预测的，只要输人了相同的数据，就都能返回相同的结果，那它就满足可重入性的要求，当然也就是线程安全的。 ¶线程封闭 当访问共享的可变数据是，如果能限制在仅在单线程内访问数据，就不需要同步。这种技术被称为线程封闭。Java元语言没有强制规定某个变量必须由锁保护，同样也无法强制将对象封闭在某个线程中。Java语言及其核心库提供了一些机制帮助维持线程封闭性，比如局部变量和ThreadLocal类。 ¶栈封闭 栈封闭上线程封闭的一种特例，在栈封闭中，只能通过局部变量才能访问对象。局部变量的固有属性之一就是封闭在执行线程中，它们位于执行线程的栈中，其他线程无法访问。 对于基本类型的局部变量，例如下面代码中loadTheArk方法中的numPairs，由于任何方法都不能获得对基本类型的引用，因此Java语言的这种语义保证了基本类型的局部变量始终封闭在线程内。 123456789101112131415161718public int loadTheArk(Collection&lt;Animal&gt; candidates)&#123; SortedSet&lt;Animal&gt; animals; int numPairs = 0; Animal candidate = null; animals = new TreeSet&lt;Animal&gt;(); animals.addAll(candidates); for (Animal a: animals)&#123; //do something numPairs++; &#125; return numPairs; &#125; 而在维持对象引用的栈封闭性时，我们需要使用一些手段保证被引用的对象不会逸出。比如我们在上面代码中实例化了一TreeSet对象，并将指向它的一个引用保存在animals中。此时，只有一个引用指向animals，这个引用被封闭在局部变量中，因此也封闭在执行线程中。然而，如果我们发布了animals的引用或者改对象中的任何数据的引用，这都会导致封闭性被破坏。 ¶ThreadLocal类 Java语言中，如果一个变量要被多线程访问，可以使用volatile关键字声明它为“易变的”:如果一个变量要被某个线程独享，就可以通过ThreadLocal类来实现线程本地存储的功能。每一个线程的Thread对象中都有一个ThreadLocalMap对象，这个对象存储了一组以ThreadLocal.threadLocalHashCode为键，以本地线程变量为值的K-V值对，ThreadLocal对象就是当前线程ThreadLocalMap的访问入口，每个ThreadLocal对象都包含一个独一无二的threadLocalHashCode值，使用这个值就可以在线程K-V值对中找回对应的本地线程变量。需要注意的是，ThreadLocal变量类似于全局变量，会降低代码的可重入性，因此使用时要格外小心。 ¶参考资料 《深入理解Java虚拟机》第四版 《Java并发编程实战》 极客时间《Java并发编程实战》]]></content>
      <categories>
        <category>java多线程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>java多线程</tag>
        <tag>线程安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程池详解]]></title>
    <url>%2Fmutlithreading%2Fthread-pool.html</url>
    <content type="text"><![CDATA[所谓线程池通俗的理解就是有一个池子，里面存放着已经创建好的线程，当有任务提交给线程池执行时，池子中的 某个线程会主动执行该任务。如果池子中的线程数量不够应付数量众多的任务时，则需要自动扩充新的线程到池子中，但是该数量是有限的，就好比池塘的水界线一样。当任务比较少的时候，池子中的线程能够自动回收，释放 资源。为了能够异步地提交任务和缓存未被处理的任务，需要有一个任务队列。 ¶前言 线程的使用： 1234Thread thread = new Thread(()-&gt;&#123; System.out.println("Hello World!");&#125;);thread.start(); 缺点： 使用一次创建一次 使用之后销毁线程 同时创建大量线程可能导致系统资源耗尽 ¶线程池 在面向对象编程中，创建和销毁对象是很费时间的，因为创建一个对象要获取内存资源或者其它更多资源。 在Java中虚拟机将试图跟踪每一个对象，以便能够在对象销毁后进行垃圾回收。所以提高服务程序效率的一个 手段就是尽可能减少创建和销毁对象的次数，特别是一些很耗资源的对象创建和销毁。 如何利用已有对象来服务就是一个解决的关键问题，这也就是&quot;池化资源&quot;技术产生的原因。 线程池是一种多线程处理形式，处理过程中将任务添加到队列，然后在创建线程后自动启动这些任务。 线程是稀缺资源，使用线程池可以减少创建和销毁线程的次数，每个工作线程都可以重复使用。 可以根据系统的承受能力，调整线程池中工作线程的数量，防止因为消耗过多内存导致服务器崩溃。 一个线程池包括以下四个基本组成部分： 线程池管理器（ThreadPool）：用于创建并管理线程池，包括创建线程池、销毁线程池，添加新任务； 工作线程（PoolWorker）：线程池中线程，在没有任务时处于等待状态，可以循环的执行任务； 任务接口（Task）：每个任务必须实现的接口，以供工作线程调度任务的执行，它主要规定了任务的入口，任务执行完后的收尾工作，任务的执行状态等； 任务队列（taskQueue）：用于存放没有处理的任务。提供一种缓冲机制。 ¶线程池的五种状态 线程池状态示意图以及五种状态的说明摘自CSDN一只逗比的程序猿 一共有五种，分别是RUNNING、SHUTDOWN、STOP、TIDYING、TERMINATED 线程池状态切换示意图 RUNNING 状态说明：线程池处在RUNNING状态时，能够接收新任务，以及对已添加的任务进行处理 状态切换：线程池的初始化状态是RUNNING。换句话说，线程池被一旦被创建，就处于RUNNING状态，并且线程池中的任务数为0 SHUTDOWN 状态说明：线程池处在SHUTDOWN状态时，不接收新任务，但能处理已添加的任务 状态切换：调用线程池的shutdown()接口时，线程池由RUNNING -&gt; SHUTDOWN 注：虽然状态已经不是RUNNING了，但是如果任务队列中还有任务的时候，线程池仍然会继续执行，具体分析请见ThreadPoolExecutor.execute()方法解析 STOP 状态说明：线程池处在STOP状态时，不接收新任务，不处理已添加的任务，并且会中断正在处理的任务 状态切换：调用线程池的shutdownNow()接口时，线程池由(RUNNING or SHUTDOWN ) -&gt; STOP TIDYING 状态说明：当所有的任务已终止，ctl记录的”任务数量”为0，线程池会变为TIDYING状态。当线程池变为TIDYING状态时，会执行钩子函数terminated()。terminated()在ThreadPoolExecutor类中是空的，若用户想在线程池变为TIDYING时，进行相应的处理；可以通过重载terminated()函数来实现 状态切换：当线程池在SHUTDOWN状态下，阻塞队列为空并且线程池中执行的任务也为空时，就会由 SHUTDOWN -&gt; TIDYING。 当线程池在STOP状态下，线程池中执行的任务为空时，就会由STOP -&gt; TIDYING TERMINATED 状态说明：线程池彻底终止，就变成TERMINATED状态 状态切换：线程池处在TIDYING状态时，执行完terminated()之后，就会由 TIDYING -&gt; TERMINATED 线程池五种状态的二进制表示 线程池状态 二进制 RUNNING 111 SHUTDOWN 000 STOP 001 TIDYING 010 TERMINATED 011 1234567891011COUNT_BITS :29RUNNING :11100000 00000000 00000000 00000000SHUTDOWN :00000000 00000000 00000000 00000000STOP :00100000 00000000 00000000 00000000TIDYING :01000000 00000000 00000000 00000000TERMINATED :01100000 00000000 00000000 00000000RUNNING :-536870912SHUTDOWN :0STOP :536870912TIDYING :1073741824TERMINATED :1610612736 ¶工作线程（PoolWorker） 工作线程是由ThreadPoolExecutor的内部类Worker类实现： 12345678910111213141516171819202122232425262728293031323334353637383940/** * Class Worker mainly maintains interrupt control state for * threads running tasks, along with other minor bookkeeping. * This class opportunistically extends AbstractQueuedSynchronizer * to simplify acquiring and releasing a lock surrounding each * task execution. This protects against interrupts that are * intended to wake up a worker thread waiting for a task from * instead interrupting a task being run. We implement a simple * non-reentrant mutual exclusion lock rather than use * ReentrantLock because we do not want worker tasks to be able to * reacquire the lock when they invoke pool control methods like * setCorePoolSize. Additionally, to suppress interrupts until * the thread actually starts running tasks, we initialize lock * state to a negative value, and clear it upon start (in * runWorker). */private final class Worker extends AbstractQueuedSynchronizer implements Runnable&#123; /** Thread this worker is running in. Null if factory fails. */ final Thread thread; /** Initial task to run. Possibly null. */ Runnable firstTask; /** * Creates with given first task and thread from ThreadFactory. * @param firstTask the first task (null if none) */ Worker(Runnable firstTask) &#123; setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); &#125; /** Delegates main run loop to outer runWorker */ public void run() &#123; runWorker(this); &#125;&#125; Worker是实现了Runnable接口，每个Worker中有一个线程属性thread,添加Worker的时候会启动该线程，该线程会循环执行任务，直到线程池停止。 ¶任务接口（Task） Runnable 1234567891011121314public interface Runnable &#123; /** * When an object implementing interface &lt;code&gt;Runnable&lt;/code&gt; is used * to create a thread, starting the thread causes the object's * &lt;code&gt;run&lt;/code&gt; method to be called in that separately executing * thread. * &lt;p&gt; * The general contract of the method &lt;code&gt;run&lt;/code&gt; is that it may * take any action whatsoever. * * @see java.lang.Thread#run() */ public abstract void run();&#125; 任务需要实现Runnable接口，实现抽象方法run,在其中编写具体的任务实现。 Callable 123456789public interface Callable&lt;V&gt; &#123; /** * Computes a result, or throws an exception if unable to do so. * * @return computed result * @throws Exception if unable to compute a result */ V call() throws Exception;&#125; 任务实现Callable接口，实现抽象方法call，这个方法有一个返回值，用于获取任务执行的结果。 提交到线程池后，会返回另一个实现了Runnable接口的RunnableFuture,其定义如下： 1234567public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; &#123; /** * Sets this Future to the result of its computation * unless it has been cancelled. */ void run();&#125; RunnableFuture接口继承了Runnable接口和Future接口，可以调用提交到线程池后返回的RunnableFuture的get方法，该方法是阻塞的，直到该任务执行完成。 123456public V get() throws InterruptedException, ExecutionException &#123; int s = state; if (s &lt;= COMPLETING) s = awaitDone(false, 0L); return report(s);&#125; ¶任务队列 任务提交到线程池后，如果没有空闲的线程来执行该任务，则会将其放到任务缓冲队列里面，该队列是一个阻塞队列： 1private final BlockingQueue&lt;Runnable&gt; workQueue; BlockingQueue4 组不同的方法用于插入、移除以及对队列中的元素进行检查。如果请求的操作不能得到立即执行的话，每个方法的表现也不同。这些方法如下： 抛出异常 特殊值 阻塞 超时 插入 add(e) offer(e) put(e) offer(e, time, unit) 移除 remove() poll() take() poll(time, unit) 检查 element() peek() 不可用 不可用 四组不同的行为方式解释: 异常 如果试图的操作无法立即执行，抛一个异常。 特定值 如果试图的操作无法立即执行，返回一个特定的值(常常是 true / false)。 阻塞 如果试图的操作无法立即执行，该方法调用将会发生阻塞，直到能够执行。 超时 如果试图的操作无法立即执行，该方法调用将会发生阻塞，直到能够执行，但等待时间不会超过给定值。返回一个特定值以告知该操作是否成功(典型的是 true / false)。 具有以下特点： 先进先出（FIFO） 不接受 null 元素 可以是限定容量的 实现主要用于生产者-使用者队列，但它另外还支持 Collection 接口 实现是线程安全的 BlockingQueue有多种实现，分别满足不同功能的线程池，这里只介绍线程池中常用的队列（其它实现有兴趣的可以深入具体学习）： ArrayBlockingQueue 一个由数组支持的有界阻塞队列。此队列按 FIFO（先进先出）原则对元素进行排序。队列的头部是在队列中存在时间最长的元素。队列的尾部 是在队列中存在时间最短的元素。新元素插入到队列的尾部，队列获取操作则是从队列头部开始获得元素。 DelayQueue Delayed 元素的一个无界阻塞队列，只有在延迟期满时才能从中提取元素。该队列的头部 是延迟期满后保存时间最长的 Delayed 元素。如果延迟都还没有期满，则队列没有头部，并且 poll 将返回 null。当一个元素的 getDelay(TimeUnit.NANOSECONDS) 方法返回一个小于等于 0 的值时，将发生到期。即使无法使用 take 或 poll 移除未到期的元素，也不会将这些元素作为正常元素对待。 LinkedBlockingQueue 内部以一个链式结构(链接节点)对其元素进行存储，满足FIFO(先进先出)原则。 SynchronousQueue SynchronousQueue 是一个特殊的队列，它的内部同时只能够容纳单个元素。如果该队列已有一元素的话，试图向队列中插入一个新元素的线程将会阻塞，直到另一个线程将该元素从队列中抽走。同样，如果该队列为空，试图向队列中抽取一个元素的线程将会阻塞，直到另一个线程向队列中插入了一条新的元素。 ¶线程池管理器 ¶类图 Executor：负责线程的使用与调度的根接口 ExecutorService：Executor的子接口，线程池的主要接口 AbstractExecutorService：实现了ExecutorService接口，基本实现了ExecutorService其中声明的所有方法，另有添加其他方法 ThreadPoolExecutor：继承了AbstractExecutorService，线程池常用实现类 ScheduledExecutorService：继承了ExecutorService，负责线程调度的接口 ScheduledThreadPoolExecutor：继承了ThreadPoolExecutor同时实现了ScheduledExecutorService ¶Executors Executors利用工厂模式向我们提供了4种线程池实现方式： newSingleThreadExecutor 创建一个单线程的线程池。这个线程池只有一个线程在工作，也就是相当于单线程串行执行所有任务。如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它。 此线程池保证所有任务的执行顺序按照任务的提交顺序执行。 拥有一个存活时间无限长的线程，排队的任务将放入无界队列，适用于一个任务一个任务执行的场景。 newFixedThreadPool 创建固定大小的线程池。每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小。 线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。 每个线程存活的时间无限，适用于执行长期的任务，例如服务器。 newCachedThreadPool 创建一个可缓存的线程池。如果线程池的大小超过了处理任务所需要的线程， 那么就会回收部分空闲（60秒不执行任务）的线程，当任务数增加时，此线程池又可以智能的添加新线程来处理任务。 此线程池不会对线程池大小做限制，线程池大小完全依赖于操作系统（或者说JVM）能够创建的最大线程大小。 可以无限增加线程数，适用于执行很多短期异步的小程序或者负载较轻的服务器。 newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行. !&gt; 阿里巴巴编码规约有一条： !&gt; 【强制】线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。 大家对线程池的了解吗，newSingleThreadExecutor、newFixedThreadPool、newCachedThreadPool、newScheduledThreadPool 这些线程池是如何实现的呢？ 创建的时候都有哪些参数呢？ ¶ThreadPoolExecutor ¶构造函数 先来看一下ThreadPoolExecutor的构造函数吧。 在这里着重介绍几个参数 阻塞队列 没有空闲的Worker时，将到达的任务加入队列中。 1.直接传递。SynchronousQueue队列的默认方式，一个存储元素的阻塞队列而是直接投递到线程中。 每一个入队操作必须等到另一个线程调用移除操作，否则入队将一直阻塞。 当处理一些可能有内部依赖的任务时，这种策略避免了加锁操作。 直接传递一般不能限制maximumPoolSizes以避免拒绝 接收新的任务。 如果新增任务的速度大于任务处理的速度就会造成增加无限多的线程的可能性。 2.无界队列。如LinkedBlockingQueue，当核心线程正在工作时，使用不用预先定义大小的无界队列将使新到来的任务处理等到中， 所以如果线程数是小于corePoolSize时，将不会创建有入队操作。这种策略将很适合那些相互独立的任务， 如Web服务器。如果新增任务的速度大于任务处理的速度就会造成无界队列一直增长的可能性。 3.有界队列。如ArrayBlockingQueue，当定义了maximumPoolSizes时使用有界队列可以预防资源的耗尽， 但是增加了调整和控制队列的难度，队列的大小和线程池的大小是相互影响的， 使用很大的队列和较小的线程池会减少CPU消耗、操作系统资源以及线程上下文开销，但却人为的降低了吞吐量。 如果任务是频繁阻塞型的（I/O），系统是可以把时间片分给多个线程的。而采用较小的队列和较大的线程池， 虽会造成CPU繁忙，但却会遇到调度开销，这也会降低吞吐量。 饱和策略（拒绝接收任务） 当Executor调用shutdown方法后或者达到工作队列的最容量时,线程池则已经饱和了，此时则不会接收新的task。但无论是何种情 况，execute方法会调用RejectedExecutionHandler#rejectedExecution方法来执行饱和策略，在线程池内部预定义了几种处理策略： 1.终止执行(AbortPolicy)。默认策略， Executor会抛出一个RejectedExecutionException运行异常到调用者线程来完成终止。 2.调用者线程来运行任务(CallerRunsPolicy)。这种策略会由调用execute方法的线程自身来执行任务， 它提供了一个简单的反馈机制并能降低新任务的提交频率。 3.丢弃策略(DiscardPolicy)。不处理，直接丢弃提交的任务。 4.丢弃队列里最近的一个任务(DiscardOldestPolicy)。如果Executor还未shutdown的话， 则丢弃工作队列的最近的一个任务，然后执行当前任务。 ¶主要属性 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778/** * The queue used for holding tasks and handing off to worker * threads. We do not require that workQueue.poll() returning * null necessarily means that workQueue.isEmpty(), so rely * solely on isEmpty to see if the queue is empty (which we must * do for example when deciding whether to transition from * SHUTDOWN to TIDYING). This accommodates special-purpose * queues such as DelayQueues for which poll() is allowed to * return null even if it may later return non-null when delays * expire. */private final BlockingQueue&lt;Runnable&gt; workQueue;/** * Lock held on access to workers set and related bookkeeping. * While we could use a concurrent set of some sort, it turns out * to be generally preferable to use a lock. Among the reasons is * that this serializes interruptIdleWorkers, which avoids * unnecessary interrupt storms, especially during shutdown. * Otherwise exiting threads would concurrently interrupt those * that have not yet interrupted. It also simplifies some of the * associated statistics bookkeeping of largestPoolSize etc. We * also hold mainLock on shutdown and shutdownNow, for the sake of * ensuring workers set is stable while separately checking * permission to interrupt and actually interrupting. */private final ReentrantLock mainLock = new ReentrantLock();/** * Set containing all worker threads in pool. Accessed only when * holding mainLock. */private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;();/** * Factory for new threads. All threads are created using this * factory (via method addWorker). All callers must be prepared * for addWorker to fail, which may reflect a system or user's * policy limiting the number of threads. Even though it is not * treated as an error, failure to create threads may result in * new tasks being rejected or existing ones remaining stuck in * the queue. * * We go further and preserve pool invariants even in the face of * errors such as OutOfMemoryError, that might be thrown while * trying to create threads. Such errors are rather common due to * the need to allocate a native stack in Thread.start, and users * will want to perform clean pool shutdown to clean up. There * will likely be enough memory available for the cleanup code to * complete without encountering yet another OutOfMemoryError. */private volatile ThreadFactory threadFactory;/** * Handler called when saturated or shutdown in execute. */private volatile RejectedExecutionHandler handler;/** * Timeout in nanoseconds for idle threads waiting for work. * Threads use this timeout when there are more than corePoolSize * present or if allowCoreThreadTimeOut. Otherwise they wait * forever for new work. */private volatile long keepAliveTime;/** * Core pool size is the minimum number of workers to keep alive * (and not allow to time out etc) unless allowCoreThreadTimeOut * is set, in which case the minimum is zero. */private volatile int corePoolSize;/** * Maximum pool size. Note that the actual maximum is internally * bounded by CAPACITY. */private volatile int maximumPoolSize; ¶任务的执行 线程池执行任务的主要方法有：execute、submit，其中submit方法会将传入的Runnable或者Callable封装成RunnableFuture然后调用execute方法， 那么任务具体是如何执行的呢？我的理解大致如下： 其代码如下： 123456789101112131415161718192021222324252627282930313233343536373839public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); /* * Proceed in 3 steps: * * 1. If fewer than corePoolSize threads are running, try to * start a new thread with the given command as its first * task. The call to addWorker atomically checks runState and * workerCount, and so prevents false alarms that would add * threads when it shouldn't, by returning false. * * 2. If a task can be successfully queued, then we still need * to double-check whether we should have added a thread * (because existing ones died since last checking) or that * the pool shut down since entry into this method. So we * recheck state and if necessary roll back the enqueuing if * stopped, or start a new thread if there are none. * * 3. If we cannot queue task, then we try to add a new * thread. If it fails, we know we are shut down or saturated * and so reject the task. */ int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; else if (!addWorker(command, false)) reject(command);&#125; execute方法简单总结如下： 如果当前线程池里面运行的线程数量小于corePoolSize，则创建新的线程（需要获取全局锁）。 如果当前线程池里面运行的线程数量大于或等于corePoolSize，则将任务加入workQueue中，缓存起来。 如果workQueue已满，但是线程数量小于maximumPoolSize，则继续添加线程（需要再次获取全局锁）。 如果线程数已达到最大线程数了，任务队列也满了，任务将被拒绝，并调用RejectedExecutionHandler的rejectExecution方法。 ¶添加工作线程addWorker 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677// 两个参数，firstTask表示需要跑的任务。boolean类型的core参数为true的话表示使用corePoolSize，为false使用maximumPoolSize// 返回值是boolean类型，true表示新任务被添加了，并且执行了。否则是falseprivate boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // 线程池当前状态 // 这个判断转换成 rs &gt;= SHUTDOWN &amp;&amp; (rs != SHUTDOWN || firstTask != null || workQueue.isEmpty)。 // 概括为3个条件： // 1. 线程池不在RUNNING状态并且状态是STOP、TIDYING或TERMINATED中的任意一种状态 // 2. 线程池不在RUNNING状态，线程池接受了新的任务 // 3. 线程池不在RUNNING状态，阻塞队列为空。 满足这3个条件中的任意一个的话，拒绝执行任务 if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; int wc = workerCountOf(c); // 线程池线程个数 // 如果线程池线程数量超过线程池最大容量或者线程数量超过了 // corePoolSize(core参数为true，core参数为false的话判断超过最大大小) if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; // 超过直接返回false if (compareAndIncrementWorkerCount(c)) // 没有超过各种大小的话，cas操作线程池线程数量+1，cas成功的话跳出循环 break retry; c = ctl.get(); // 重新检查状态 if (runStateOf(c) != rs) // 如果状态改变了，重新循环操作 continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; // 走到这一步说明cas操作成功了，线程池线程数量+1 boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; final ReentrantLock mainLock = this.mainLock; w = new Worker(firstTask); // 基于任务firstTask构造worker final Thread t = w.thread; // 使用Worker的属性thread，这个thread是使用ThreadFactory构造出来的 if (t != null) &#123; // ThreadFactory构造出的Thread有可能是null，做个判断 mainLock.lock(); // 得到线程池的可重入锁 try &#123; // 在锁住之后再重新检测一下状态 int c = ctl.get(); int rs = runStateOf(c); // 如果线程池在RUNNING状态或者线程池在SHUTDOWN状态并且任务是个null if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // 判断线程是否还活着，也就是说线程已经启动并且还没死掉 throw new IllegalThreadStateException(); // 如果存在已经启动并且还没死的线程，抛出异常 workers.add(w); // worker添加到线程池的workers属性中，是个HashSet int s = workers.size(); // 得到目前线程池中的线程个数 // 如果线程池中的线程个数超过了线程池中的最大线程数时，更新一下这个最大线程数 if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; // 标识一下Worker已经添加成功 &#125; &#125; finally &#123; mainLock.unlock(); // 解锁 &#125; if (workerAdded) &#123; // 如果Worker添加成功，运行任务 t.start(); // 启动线程，启动Worker workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) // 如果任务启动失败，调用addWorkerFailed方法 addWorkerFailed(w); &#125; return workerStarted;&#125; 工作线程添加的方法基本了解了，那么这个Worker是如何运行的呢，又是如何重用，如何执行多个任务的呢？ ¶工作线程的运行 Worker在addWorker方法中，当Worker成功添加到workers后，调用Worker.thread启动Worker，在前面Worker的介绍中了解到run方法直接调用了 ThreadPoolExecutor.runWorker方法具体执行任务，ThreadPoolExecutor.runWorker代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); // 得到当前线程 Runnable task = w.firstTask; // 得到Worker中的任务task，也就是用户传入的task w.firstTask = null; // 将Worker中的任务置空 w.unlock(); // allow interrupts。 boolean completedAbruptly = true; // 标识当前Worker异常结束，默认是异常结束 try &#123; // 如果worker中的任务不为空，执行执行任务 // 否则使用getTask获得任务。一直循环，除非得到的任务为空才退出 while (task != null || (task = getTask()) != null) &#123; // 如果拿到了任务，给自己上锁，表示当前Worker已经要开始执行任务了， // 已经不是处于闲置Worker(闲置Worker的解释请看下面的线程池关闭) w.lock(); // 在执行任务之前先做一些处理。 // 1. 如果线程池已经处于STOP状态并且当前线程没有被中断，中断线程 // 2. 如果线程池还处于RUNNING或SHUTDOWN状态，并且当前线程已经被中断了， // 重新检查一下线程池状态，如果处于STOP状态并且没有被中断，那么中断线程 if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; // 任务执行前需要做什么，ThreadPoolExecutor是个空实现，子类可以自行扩展 beforeExecute(wt, task); Throwable thrown = null; try &#123; // 真正的开始执行任务，这里run的时候可能会被中断，比如线程池调用了shutdownNow方法 task.run(); &#125; catch (RuntimeException x) &#123; // 任务执行发生的异常全部抛出，不在runWorker中处理 thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; // 任务执行结束需要做什么，ThreadPoolExecutor是个空实现，子类可以自行扩展 afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; // 记录执行任务的个数 w.unlock(); // 执行完任务之后，解锁，Worker变成闲置Worker，等待执行下一个任务 &#125; &#125; completedAbruptly = false; // 正常结束 &#125; finally &#123; processWorkerExit(w, completedAbruptly); // Worker退出时执行 &#125;&#125; Worker正常结束或者异常结束时都会调用processWorkerExit方法，当Worker异常结束时（比如执行的任务中抛出了未处理的异常）可能会重新创建一个新的Worker替换上。 processWorkerExit具体实现如下： 123456789101112131415161718192021222324252627282930313233private void processWorkerExit(Worker w, boolean completedAbruptly) &#123; // 如果Worker没有正常结束流程调用processWorkerExit方法，worker数量减一。 // 如果是正常结束的话，在getTask方法里worker数量已经减一了 if (completedAbruptly) decrementWorkerCount(); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); // 加锁，防止并发问题 try &#123; completedTaskCount += w.completedTasks; // 记录总的完成任务数 workers.remove(w); // 线程池的worker集合删除掉需要回收的Worker &#125; finally &#123; mainLock.unlock(); // 解锁 &#125; tryTerminate(); // 尝试结束线程池 int c = ctl.get(); if (runStateLessThan(c, STOP)) &#123; // 如果线程池还未停止，处于RUNNING或者SHUTDOWN状态 if (!completedAbruptly) &#123; // Worker是正常结束流程的话 int min = allowCoreThreadTimeOut ? 0 : corePoolSize; // 核心线程允许超过空闲时间回收 if (min == 0 &amp;&amp; ! workQueue.isEmpty()) min = 1; if (workerCountOf(c) &gt;= min) // 还有在工作的Worker return; // 不需要新开一个Worker &#125; // 新开一个Worker代替原先的Worker // 新开一个Worker有以下几种情况 // 1. 用户执行的任务发生了异常 // 2. Worker正常退出，Worker数量比线程池corePoolSize小，阻塞队列不空但是没有任何Worker在工作 addWorker(null, false); &#125;&#125; ¶线程池的关闭 shutdown方法，关闭线程池，关闭之后阻塞队列里的任务不受影响，会继续被Worker处理，但是新的任务不会被接受，方法实现如下： 12345678910111213public void shutdown() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); // 关闭的时候需要加锁，防止并发 try &#123; checkShutdownAccess(); // 检查关闭线程池的权限 advanceRunState(SHUTDOWN); // 把线程池状态更新到SHUTDOWN interruptIdleWorkers(); // 中断闲置的Worker onShutdown(); // 钩子方法，默认不处理。ScheduledThreadPoolExecutor会做一些处理 &#125; finally &#123; mainLock.unlock(); // 解锁 &#125; tryTerminate(); // 尝试结束线程池&#125; interruptIdleWorkers方法，注意，这个方法打断的是闲置Worker，打断闲置Worker之后，getTask方法会返回null，然后Worker会被回收。那什么是闲置Worker呢？ 闲置Worker是这样解释的：Worker运行的时候会去阻塞队列拿数据(getTask方法)，拿的时候如果没有设置超时时间，那么会一直阻塞等待阻塞队列进数据，这样的Worker就被称为闲置Worker。 由于Worker也是一个AQS(AbstractQueuedSynchronizer,详解点击这里)，在runWorker方法里会有一对lock和unlock操作，这对lock操作是为了确保Worker不是一个闲置Worker。 所以Worker被设计成一个AQS是为了根据Worker的锁来判断是否是闲置线程，是否可以被强制中断。我们来看看它的实现： 1234567891011121314151617181920212223242526272829// 调用他的一个重载方法，传入了参数false，表示要中断所有的正在运行的闲置Worker，如果为true表示只打断一个闲置Workerprivate void interruptIdleWorkers() &#123; interruptIdleWorkers(false);&#125;private void interruptIdleWorkers(boolean onlyOne) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); // 中断闲置Worker需要加锁，防止并发 try &#123; for (Worker w : workers) &#123; Thread t = w.thread; // 拿到worker中的线程 // Worker中的线程没有被打断并且Worker可以获取锁，这里Worker能获取锁说明Worker是个闲置Worker， // 在阻塞队列里拿数据一直被阻塞，没有数据进来。如果没有获取到Worker锁，说明Worker还在执行任务， // 不进行中断(shutdown方法不会中断正在执行的任务) if (!t.isInterrupted() &amp;&amp; w.tryLock()) &#123; try &#123; t.interrupt(); // 中断Worker线程 &#125; catch (SecurityException ignore) &#123; &#125; finally &#123; w.unlock(); // 释放Worker锁 &#125; &#125; if (onlyOne) // 如果只打断1个Worker的话，直接break退出，否则，遍历所有的Worker break; &#125; &#125; finally &#123; mainLock.unlock(); // 解锁 &#125;&#125; 从上面的代码可以看到，shutdown并不会立即停止线程池（shutdownNow会立即停止线程池），而是先将线程状态置于SHUTDOWN，然后中断闲置的Worker。 然后尝试结束线程池，tryTerminate的实现如下： 1234567891011121314151617181920212223242526272829303132333435363738final void tryTerminate() &#123; for (;;) &#123; int c = ctl.get(); // 满足3个条件中的任意一个，不终止线程池 // 1. 线程池还在运行，不能终止 // 2. 线程池处于TIDYING或TERMINATED状态，说明已经在关闭了，不允许继续处理 // 3. 线程池处于SHUTDOWN状态并且阻塞队列不为空，这时候还需要处理阻塞队列的任务，不能终止线程池 if (isRunning(c) || runStateAtLeast(c, TIDYING) || (runStateOf(c) == SHUTDOWN &amp;&amp; ! workQueue.isEmpty())) return; // 走到这一步说明线程池已经不在运行，阻塞队列已经没有任务，但是还要回收正在工作的Worker if (workerCountOf(c) != 0) &#123; // 由于线程池不运行了，调用了线程池的关闭方法 // 中断闲置Worker，直到回收全部的Worker。这里没有那么暴力，只中断一个，中断之后退出方法， // 中断了Worker之后，Worker会回收，然后还是会调用tryTerminate方法，如果还有闲置线程，那么继续中断 interruptIdleWorkers(ONLY_ONE); return; &#125; // 走到这里说明worker已经全部回收了，并且线程池已经不在运行，阻塞队列已经没有任务。可以准备结束线程池了 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); // 加锁，防止并发 try &#123; if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) &#123; // cas操作，将线程池状态改成TIDYING try &#123; terminated(); // 调用terminated方法 &#125; finally &#123; ctl.set(ctlOf(TERMINATED, 0)); // terminated方法调用完毕之后，状态变为TERMINATED termination.signalAll(); &#125; return; &#125; &#125; finally &#123; mainLock.unlock(); // 解锁 &#125; // else retry on failed CAS &#125;&#125; ¶简单实战 好了关于线程池的简单介绍就到这里了，我们接下来看一个小小的例子，顺便了解一下线程池的参数选择。 线程数的选择常见策略如下： CPU密集型任务 尽量使用较小的线程池，一般为CPU核心数+1。 因为CPU密集型任务使得CPU使用率很高，若开过多的线程数，只能增加上下文切换的次数，因此会带来额外的开销。 IO密集型任务 可以使用稍大的线程池，一般为2*CPU核心数。 IO密集型任务CPU使用率并不高，因此可以让CPU在等待IO的时候去处理别的任务，充分利用CPU时间。 混合型任务 可以将任务分成IO密集型和CPU密集型任务，然后分别用不同的线程池去处理。 只要分完之后两个任务的执行时间相差不大，那么就会比串行执行来的高效。 因为如果划分之后两个任务执行时间相差甚远，那么先执行完的任务就要等后执行完的任务，最终的时间仍然取决于后执行完的任务，而且还要加上任务拆分与合并的开销，得不偿失。 通过前面了解到ThreadPoolExecutor的饱和策略默认选择的是AbortPolicy策略，新来的任务将被丢弃，即使保证任务不丢弃的策略CallerRunsPolicy也是直接调用任务的run方法来实现。 我们如何实现一个满足生产者消费者模型的线程池呢，这里将Worker当做消费者，可以同时处理多个生产者提交的任务，同时要保证生产者过多时任务不被丢弃。具体代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/** * package com.teddy.thread * description: 线程池工具类 * Copyright 2018 Teddy, Inc. All rights reserved. * * @author Teddy * @date 2018-9-16 14:20 */public class ThreadPoolUtils &#123; /** * 任务等待队列 容量 */ private static final int TASK_QUEUE_SIZE = 1000; /** * 空闲线程存活时间 单位分钟 */ private static final long KEEP_ALIVE_TIME = 10L; /** * 任务执行线程池 */ private static ThreadPoolExecutor threadPool; static &#123; int corePoolNum = 2 * Runtime.getRuntime().availableProcessors() + 1; int maximumPoolSize = 2 * corePoolNum; threadPool = new ThreadPoolExecutor( corePoolNum, maximumPoolSize, KEEP_ALIVE_TIME, TimeUnit.MINUTES, new ArrayBlockingQueue&lt;&gt;(TASK_QUEUE_SIZE), new ThreadFactoryBuilder().setNameFormat("ThreadPoolUtils-%d").build(), (r, executor) -&gt; &#123; if (!executor.isShutdown()) &#123; try &#123; executor.getQueue().put(r); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); Thread.currentThread().interrupt(); &#125; &#125; &#125;); &#125; /** * Description: 执行任务 * * @param task 任务 * @author teddy * @date 2018/9/16 */ public static void execute(Runnable task) &#123; threadPool.execute(task); &#125; /** * Description: 提交任务到线程池 * * @param task 任务 * * @return Future&lt;T&gt; * @author teddy * @date 2019/3/23 */ public static &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task)&#123; return threadPool.submit(task); &#125;&#125;]]></content>
      <categories>
        <category>java多线程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>java多线程</tag>
        <tag>ThreadPool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单例模式]]></title>
    <url>%2Fdesign-patterns%2Fsingleton-pattern.html</url>
    <content type="text"><![CDATA[在GoF的23种设计模式中，单例模式是比较简单的一种。然而，有时候越是简单的东西越容易出现问题。下面就单例设计模式详细的探讨一下。 所谓单例模式，简单来说，就是在整个应用中保证只有一个类的实例存在。就像是Java Web中的application，也就是提供了一个全局变量，用处相当广泛，比如保存全局数据，实现全局性的操作等。 ¶最简单实现(饿汉) 1234567891011public class Singleton&#123; private static final Singleton singleton = new Singleton(); public static Singleton getInstance()&#123; return singleton; &#125; private Singleton()&#123; &#125;&#125; 外部使用者如果需要使用SingletonClass的实例，只能通过getInstance()方法，并且它的构造方法是private的，这样就保证了只能有一个对象存在。 ¶性能优化–lazy loaded(懒汉) 上面的代码虽然简单，但是有一个问题----无论这个类是否被使用，都会创建一个instance对象。如果这个创建很耗时，比如说链接10000次数据库（夸张一点啦…），并且这个类还不一定会被使用，那么这个创建过程就是无用的，怎么办呢？ 1234567891011121314public class SingletonClass &#123; private static SingletonClass instance = null; public static SingletonClass getInstance() &#123; if(instance == null) &#123; instance = new SingletonClass(); &#125; return instance; &#125; private SingletonClass() &#123; &#125;&#125; 要使用 SingletonClass，调用getInstance（）方法，第一次的时候发现instance时null,然后就创建一个对象，返回出去；第二次再使用的时候，因为这个instance是static的，共享一个内存地址的，所以instance的值已经不是null了，因此不会再创建对象，直接将其返回。这个过程就称为lazyloaded,也就是迟加载-----直到使用的时候才经行加载。 ¶线程安全 上面的代码很清楚，也很简单。然而就像那句名言：“80%的错误是由20%的代码优化引起的”。单线程下，这段代码没什么问题，可是如果是多线程呢，麻烦就来了，我们来分析一下： 线程A希望使用SingletonClass，调用getInstance()方法。因为是第一次调用，A就发现instance是null的，于是它开始创建实例，就在这个时候，CPU发生时间片切换， 线程B开始执行，它要使用SingletonClass，调用getInstance()方法，同样检测到instance是null——注意，这是在A检测完之后切换的，也就是说A并没有来得及创建对象——因此B开始创建。 B创建完成后，切换到A继续执行，因为它已经检测完了，所以A不会再检测一遍，它会直接创建对象。这样，线程A和B各自拥有一个SingletonClass的对象——单例失败！ 解决的办法也很简单，那就是加锁： 123456789101112public class SingletonClass&#123; private static SingletonClass instance = null; public synchronized static SingletonClass getInstance()&#123; if(instance == null)&#123; instance = new SingletonClass(); &#125; return instance; &#125; private SingletonClass()&#123; &#125; &#125; 只要getInstance（）加上同步锁，，一个线程必须等待另外一个线程创建完后才能使用这个方法，这就保证了单例的唯一性。 ¶双重检查锁定(double–checked–locking) 上面这段代码毫无疑问存在性能的问题----synchronized修饰的同步块可是要比一般的代码慢上几倍的！如果存在很多次的getInstance()调用，那性能问题就不得不考虑了？！！！ 究竟是整个方法都必须加锁，还是紧紧其中某一句加锁就足够了？我们为什么要加锁呢？分析一下lazy loaded的那种情形的原因，原因就是检测null的操作和创建对象的操作分离了，导致出现只有加同步锁才能单利的唯一性。 如果这俩个操作能够原子的进行，那么单利就已经保证了。于是，我们开始修改代码： 1234567891011121314public class SingletonClass&#123; private static SingletonClass instance = null; public static SingletonClass getInstance()&#123; synchronized(SingletonClass.class)&#123; if(instance == null)&#123; instance = new SingletonClass(); &#125; &#125; return instance; &#125; private SingletonClass()&#123; &#125; &#125; 首先去掉 getInstance() 的同步操作，然后把同步锁加载到if语句上。但是，这样的修改起不到任何作用：因为每次调用getInstance()的时候必然要经行同步，性能的问题还是存在。如果…我们事先判断一下是不是为null在去同步呢？ 12345678910111213141516public class SingletonClass&#123; private static SingletonClass instance = null; public static SingletonClass getInstance()&#123; if(instance == null)&#123; synchronized(SingletonClass.class)&#123; if(instance == null)&#123; instance = new SingletonClass(); &#125; &#125; &#125; return instance; &#125; private SingletonClass()&#123; &#125; &#125; 首先判断instance是不是为null，如果为null在去进行同步，如果不为null，则直接返回instance对象。这就是double—checked----locking设计实现单例模式。 ¶并发编程–有序性 并发编程中，我们通常会遇到以下三个问题：原子性问题，可见性问题，有序性问题。我们上面的单例实现是否都解决了。 [X] 原子性：即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。 [X] 可见性：可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。 [ ] 有序性：即程序执行的顺序按照代码的先后顺序执行。 编译原理里面有一个很重要的内容是编译器优化。所谓编译器优化是指，在不改变原来语义的情况下，通过调整语句顺序，来让程序运行的更快。这称为指令重排序(Instruction Reorder)。 初始化Singleton和将对象地址赋给instance字段的顺序是不确定的。在某个线程创建单例对象时，在构造方法被调用之前，就为该对象分配了内存空间并将分配的内存地址赋值给instance字段了，然而该对象可能还没有初始化。若紧接着另外一个线程来调用getInstance，此时instance不是null，但取到的对象还未真正初始化，程序就会出错。 在JDK1.5之前，volatile是个关键字，但是并没有明确的规定其用途。在JDK1.5之后，volatile关键字有了明确的语义—是禁止指令重排序优化，被volatile修饰的写变量不能和之前的读写代码调整，读变量不能和之后的读写代码调整！因此，只要我们简单的把instance加上volatile关键字就可以了。 12345678910111213141516public class SingletonClass&#123; private static volatile SingletonClass instance = null; public static SingletonClass getInstance()&#123; if(instance == null)&#123; synchronized(SingletonClass.class)&#123; if(instance == null)&#123; instance = new SingletonClass(); &#125; &#125; &#125; return instance; &#125; private SingletonClass()&#123; &#125; &#125; ¶静态内部类 代码如下： 12345678910111213public class SingletonClass &#123; private static class SingletonClassInstance &#123; private static final SingletonClass instance = new SingletonClass(); &#125; public static SingletonClass getInstance() &#123; return SingletonClassInstance.instance; &#125; private SingletonClass() &#123; &#125; &#125; SingletonClass没有static的属性，因此并不会被初始化。直到调用getInstance()的时候，会首先加载SingletonClassInstance类，这个类有一个static的SingletonClass实例，因此需要调用SingletonClass的构造方法，然后getInstance()将把这个内部类的instance返回给使用者。由于这个instance是static的，因此并不会构造多次。 由于SingletonClassInstance是私有静态内部类，所以不会被其他类知道，同样，static语义也要求不会有多个实例存在。并且，JSL规范定义，类的构造必须是原子性的，非并发的，因此不需要加同步块。同样，由于这个构造是并发的，所以getInstance()也并不需要加同步。 ¶序列化问题（枚举、readResolve） 1234567891011121314151617public class SingletonClass &#123; private static class SingletonClassInstance &#123; private static final SingletonClass instance = new SingletonClass(); &#125; public static SingletonClass getInstance() &#123; return SingletonClassInstance.instance; &#125; private SingletonClass() &#123; &#125; private Object readResolve()&#123; return SingletonClassInstance.instance; &#125;&#125; JVM从内存中反序列化地&quot;组装&quot;一个新对象时,就会自动调用这个 readResolve方法来返回我们指定好的对象了, 单例规则也就得到了保证。 ¶枚举 1234public enum Singleton&#123; instance; public void whateverMethod()&#123;&#125; &#125; 使用枚举除了线程安全和防止反射调用构造器之外，还提供了自动序列化机制，防止反序列化的时候创建新的对象。因此，《Effective Java》作者推荐使用的方法。 ¶反射问题（第二次实例化的时候，抛出异常） 12345678910111213141516171819public class SingletonClass &#123; private static boolean isInstanced = false; private static class SingletonClassInstance &#123; private static final SingletonClass instance = new SingletonClass(); &#125; public static SingletonClass getInstance() &#123; return SingletonClassInstance.instance; &#125; private SingletonClass() &#123; if(!instanced)&#123; instanced = true; &#125;else&#123; throw new Exception("duplicate instance create error!" + SingletonClass.class.getName()); &#125; &#125; &#125;]]></content>
      <categories>
        <category>java设计模式</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
</search>
